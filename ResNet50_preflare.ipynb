{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dae5123-2010-47f4-b44c-a7e7de0b4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import float32\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import Augmentor\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4536e209-ac28-4772-860d-7188b3baaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7f8eaf-4c5e-4958-a533-b2ea475cd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = './data/train'\n",
    "VAL_DATA_DIR = './data/val'\n",
    "TEST_DATA_DIR = './data/test'\n",
    "\n",
    "AUG_TRAIN_DATA_DIR = './data_augmented/train'\n",
    "AUG_VAL_DATA_DIR = './data_augmented/val'\n",
    "AUG_TEST_DATA_DIR = './data_augmented/test'\n",
    "\n",
    "CHECKPOINTS_DIR = './resnet50_weights/checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0159f28-d7ff-4a2b-8c68-d9523b0097cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c998e73-948d-471b-9f49-2fbeed37e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train_data():\n",
    "    delete_files(f'{AUG_TRAIN_DATA_DIR}/positive')\n",
    "    delete_files(f'{AUG_TRAIN_DATA_DIR}/negative')\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(TRAIN_DATA_DIR):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            img = np.load(filepath)\n",
    "            # rotated_imgs = [rotate_img(img, 90), rotate_img(img, 180), rotate_img(img, 270)]\n",
    "            # for idx, rot_img in enumerate(rotated_imgs):\n",
    "            #     rotated_img_save = os.path.join(subdir, f'{file}_{idx}_rot')\n",
    "            #     np.save(rotated_img_save, rot_img)\n",
    "\n",
    "            fliplr_img = np.fliplr(img)\n",
    "            flipud_img = np.flipud(img)\n",
    "            folder = subdir.rsplit('/', 1)[1]\n",
    "            cut_filename = file.rsplit('.', 1)[0]\n",
    "\n",
    "            original_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', cut_filename)\n",
    "            fliplr_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', f'{cut_filename}_fliplr')\n",
    "            flipud_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', f'{cut_filename}_flipud')\n",
    "\n",
    "            np.save(original_img_save, img)\n",
    "            np.save(fliplr_img_save, fliplr_img)\n",
    "            np.save(flipud_img_save, flipud_img)\n",
    "\n",
    "            # translated_img = translate(img)\n",
    "            # translated_img_save = os.path.join(subdir, f'{file}_trans')\n",
    "            # np.save(translated_img_save, translated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012799a2-6a76-472d-b131-d87d9c6e4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d3de72-ac1d-4d80-8324-4c24520ab76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_paths,\n",
    "                 batch_size,\n",
    "                 input_size=(128, 128, 1),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.files_paths = files_paths.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.n = len(self.files_paths)\n",
    "        self.n_category = 2\n",
    "        # self.n_name = df[y_col['name']].nunique()\n",
    "        # self.n_type = df[y_col['type']].nunique()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.files_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.files_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        # image = preprocessing.normalize(np.load(path))\n",
    "        image = np.load(path)\n",
    "        image = cv2.resize(image, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "        return image\n",
    "\n",
    "    def __get_output(self, path, num_classes=2):\n",
    "        label = None\n",
    "        folder = path.rsplit('/')[-2]\n",
    "        if folder == 'positive':\n",
    "            label = 1\n",
    "        elif folder == 'negative':\n",
    "            label = 0\n",
    "        return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "        # path_batch = batches[self.X_col['path']]\n",
    "        # category_batch = batches[self.y_col['type']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in batches])\n",
    "        y_batch = np.asarray([self.__get_output(y, self.n_category) for y in batches])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96deae2f-d7af-44f7-8083-2f2a20a1f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "  \n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3411fa5-775b-478b-9c01-a6b2970f4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "   \n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf297fe-1860-4847-b4da-d2e0e78a304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(include_top=True, weights=None,\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=2):\n",
    "    \"\"\"Instantiates the ResNet50 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    #if weights == 'imagenet' and include_top and classes != 15:\n",
    "    #    raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "    #                     ' as true, `classes` should be 15')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    \n",
    "    # input_shape = _obtain_input_shape(input_shape,\n",
    "    #                                   default_size=256,\n",
    "    #                                   min_size=197,\n",
    "    #                                   data_format=K.image_data_format(),\n",
    "    #                                   require_flatten=include_top)\n",
    "    \n",
    "    input_shape = (128, 128, 1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "            \n",
    "    print(K.image_data_format())\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = AveragePooling2D((4, 4), name='avg_pool')(x)\n",
    "\n",
    "#     # x = Flatten()(x)\n",
    "#     # x = Dense(1, activation='sigmoid', name='fc2')(x)\n",
    "    \n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(2, activation='softmax', name='fc2')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    # x = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57df7307-f1fa-44db-b3be-19567b1eb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for subdir, dirs, files in os.walk(AUG_TRAIN_DATA_DIR):\n",
    "     for f in files:\n",
    "        train_files.append(os.path.join(subdir, f))\n",
    "train_files = np.array(train_files)\n",
    "\n",
    "val_files = []\n",
    "for subdir, dirs, files in os.walk(AUG_VAL_DATA_DIR):\n",
    "     for f in files:\n",
    "        val_files.append(os.path.join(subdir, f))\n",
    "val_files = np.array(val_files)\n",
    "\n",
    "test_files = []\n",
    "for subdir, dirs, files in os.walk(AUG_TEST_DATA_DIR):\n",
    "     for f in files:\n",
    "        test_files.append(os.path.join(subdir, f))\n",
    "test_files = np.array(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed9d87f-7d7f-4dc7-8519-f76b5f99c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = CustomDataGen(train_files, 64)\n",
    "valgen = CustomDataGen(val_files, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd12fa16-baa0-4e20-889d-3b5e955389bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 19:16:19.812286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-21 19:16:20.439349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6656 MB memory:  -> device: 0, name: GeForce RTX 2080, pci bus id: 0000:82:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "model = ResNet50(include_top=True)\n",
    "adam_fine = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17f1c8f8-bb94-404a-b613-e1513d1c0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 19:16:27.534569: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-07-21 19:16:28.231498: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-07-21 19:16:28.236176: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 20s 145ms/step - loss: 1.2166 - accuracy: 0.4996 - val_loss: 3.0121 - val_accuracy: 0.5260\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 10s 130ms/step - loss: 0.7323 - accuracy: 0.5188 - val_loss: 0.8014 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 10s 130ms/step - loss: 0.7140 - accuracy: 0.5312 - val_loss: 0.8139 - val_accuracy: 0.4896\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.7194 - accuracy: 0.5443 - val_loss: 0.8331 - val_accuracy: 0.4948\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.7075 - accuracy: 0.5425 - val_loss: 0.7728 - val_accuracy: 0.4948\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6960 - accuracy: 0.5595 - val_loss: 0.8102 - val_accuracy: 0.4792\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 10s 130ms/step - loss: 0.6948 - accuracy: 0.5497 - val_loss: 0.7263 - val_accuracy: 0.4948\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.7125 - accuracy: 0.5651 - val_loss: 0.6792 - val_accuracy: 0.5365\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6983 - accuracy: 0.5565 - val_loss: 0.6833 - val_accuracy: 0.5260\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6836 - accuracy: 0.5749 - val_loss: 0.7150 - val_accuracy: 0.5469\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6870 - accuracy: 0.5817 - val_loss: 0.8305 - val_accuracy: 0.5365\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6797 - accuracy: 0.5771 - val_loss: 0.6864 - val_accuracy: 0.5208\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6744 - accuracy: 0.5903 - val_loss: 0.7037 - val_accuracy: 0.5521\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6737 - accuracy: 0.5877 - val_loss: 0.6898 - val_accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6767 - accuracy: 0.5883 - val_loss: 0.9291 - val_accuracy: 0.5156\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6724 - accuracy: 0.5946 - val_loss: 0.6905 - val_accuracy: 0.5573\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6712 - accuracy: 0.6004 - val_loss: 0.6832 - val_accuracy: 0.5938\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6560 - accuracy: 0.6060 - val_loss: 0.7192 - val_accuracy: 0.5521\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6666 - accuracy: 0.5962 - val_loss: 0.6978 - val_accuracy: 0.5677\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6528 - accuracy: 0.6226 - val_loss: 0.6517 - val_accuracy: 0.5990\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6521 - accuracy: 0.6186 - val_loss: 0.6477 - val_accuracy: 0.5833\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6412 - accuracy: 0.6300 - val_loss: 0.7658 - val_accuracy: 0.5625\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6299 - accuracy: 0.6418 - val_loss: 0.6770 - val_accuracy: 0.5833\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6246 - accuracy: 0.6422 - val_loss: 0.6571 - val_accuracy: 0.6198\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6091 - accuracy: 0.6679 - val_loss: 0.7270 - val_accuracy: 0.5573\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.5926 - accuracy: 0.6819 - val_loss: 0.6448 - val_accuracy: 0.6250\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.5920 - accuracy: 0.6793 - val_loss: 0.6221 - val_accuracy: 0.6406\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.5763 - accuracy: 0.6933 - val_loss: 0.5967 - val_accuracy: 0.6719\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.5557 - accuracy: 0.7115 - val_loss: 0.6523 - val_accuracy: 0.6250\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.5050 - accuracy: 0.7572 - val_loss: 0.7000 - val_accuracy: 0.6094\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.4949 - accuracy: 0.7574 - val_loss: 0.6400 - val_accuracy: 0.6354\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.4482 - accuracy: 0.7863 - val_loss: 0.6380 - val_accuracy: 0.6615\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.4156 - accuracy: 0.8101 - val_loss: 0.5987 - val_accuracy: 0.7031\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.3630 - accuracy: 0.8333 - val_loss: 0.5779 - val_accuracy: 0.7292\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.3263 - accuracy: 0.8542 - val_loss: 0.6237 - val_accuracy: 0.7344\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.2768 - accuracy: 0.8850 - val_loss: 0.6525 - val_accuracy: 0.6510\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.2442 - accuracy: 0.8966 - val_loss: 0.6679 - val_accuracy: 0.7812\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.2415 - accuracy: 0.8998 - val_loss: 0.6439 - val_accuracy: 0.7656\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1950 - accuracy: 0.9197 - val_loss: 0.7377 - val_accuracy: 0.7448\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1775 - accuracy: 0.9301 - val_loss: 0.6644 - val_accuracy: 0.7656\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1466 - accuracy: 0.9427 - val_loss: 0.7004 - val_accuracy: 0.7760\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1311 - accuracy: 0.9485 - val_loss: 0.6635 - val_accuracy: 0.7240\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1278 - accuracy: 0.9501 - val_loss: 0.6450 - val_accuracy: 0.8125\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1085 - accuracy: 0.9603 - val_loss: 0.7262 - val_accuracy: 0.7604\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0857 - accuracy: 0.9688 - val_loss: 0.7527 - val_accuracy: 0.7812\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0715 - accuracy: 0.9728 - val_loss: 0.7400 - val_accuracy: 0.8073\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0791 - accuracy: 0.9692 - val_loss: 0.7709 - val_accuracy: 0.7812\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0899 - accuracy: 0.9657 - val_loss: 0.8633 - val_accuracy: 0.7604\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0644 - accuracy: 0.9756 - val_loss: 0.8046 - val_accuracy: 0.8021\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0746 - accuracy: 0.9748 - val_loss: 0.7388 - val_accuracy: 0.8073\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 0.7723 - val_accuracy: 0.7917\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0605 - accuracy: 0.9786 - val_loss: 0.8163 - val_accuracy: 0.8021\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 1.0120 - val_accuracy: 0.7604\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.8825 - val_accuracy: 0.7708\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 0.8404 - val_accuracy: 0.8073\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.0519 - accuracy: 0.9820 - val_loss: 0.7206 - val_accuracy: 0.8542\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0493 - accuracy: 0.9828 - val_loss: 0.9180 - val_accuracy: 0.7865\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 0.8925 - val_accuracy: 0.8177\n",
      "Epoch 59/100\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 0.8563 - val_accuracy: 0.7656\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0546 - accuracy: 0.9814 - val_loss: 0.7118 - val_accuracy: 0.8021\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0459 - accuracy: 0.9828 - val_loss: 0.7345 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.7274 - val_accuracy: 0.8177\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0337 - accuracy: 0.9880 - val_loss: 0.8878 - val_accuracy: 0.8229\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.7127 - val_accuracy: 0.8125\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.8254 - val_accuracy: 0.8073\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.6944 - val_accuracy: 0.8177\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.7939 - val_accuracy: 0.8542\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 0.9248 - val_accuracy: 0.8490\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0433 - accuracy: 0.9844 - val_loss: 0.8704 - val_accuracy: 0.7969\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0517 - accuracy: 0.9812 - val_loss: 0.7076 - val_accuracy: 0.8229\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.6093 - val_accuracy: 0.8646\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.9111 - val_accuracy: 0.8073\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.9294 - val_accuracy: 0.8177\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.9101 - val_accuracy: 0.8177\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0341 - accuracy: 0.9910 - val_loss: 0.9047 - val_accuracy: 0.8125\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0291 - accuracy: 0.9914 - val_loss: 0.7864 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.8523 - val_accuracy: 0.8021\n",
      "Epoch 78/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.8498 - val_accuracy: 0.8542\n",
      "Epoch 79/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.7158 - val_accuracy: 0.8490\n",
      "Epoch 80/100\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.9515 - val_accuracy: 0.8177\n",
      "Epoch 81/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.9804 - val_accuracy: 0.7812\n",
      "Epoch 82/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.9978 - val_accuracy: 0.7917\n",
      "Epoch 83/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.9613 - val_accuracy: 0.8125\n",
      "Epoch 84/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 0.9910 - val_accuracy: 0.8385\n",
      "Epoch 85/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.9438 - val_accuracy: 0.8021\n",
      "Epoch 86/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.7500 - val_accuracy: 0.8542\n",
      "Epoch 87/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.7574 - val_accuracy: 0.8438\n",
      "Epoch 88/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.8884 - val_accuracy: 0.8281\n",
      "Epoch 89/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.8165 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.8205 - val_accuracy: 0.8490\n",
      "Epoch 91/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.9008 - val_accuracy: 0.8385\n",
      "Epoch 92/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0187 - accuracy: 0.9926 - val_loss: 0.8735 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 0.7839 - val_accuracy: 0.8698\n",
      "Epoch 94/100\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.9056 - val_accuracy: 0.8646\n",
      "Epoch 95/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 1.0582 - val_accuracy: 0.8385\n",
      "Epoch 96/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 1.0713 - val_accuracy: 0.8281\n",
      "Epoch 97/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.8273 - val_accuracy: 0.8438\n",
      "Epoch 98/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.7522 - val_accuracy: 0.8490\n",
      "Epoch 99/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 1.0568 - val_accuracy: 0.8125\n",
      "Epoch 100/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.9926 - val_accuracy: 0.8229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f551c2cf370>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=adam_fine,metrics=['accuracy'])\n",
    "\n",
    "model.fit(traingen, validation_data = valgen, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70e677c-667a-4af8-8dfe-d40bd145a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'{CHECKPOINTS_DIR}/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593785c-312e-4a93-b529-2cfc5c955a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x_pos = get_data_array(f'{TEST_DATA_DIR}/positive')\n",
    "# test_x_neg = get_data_array(f'{TEST_DATA_DIR}/negative')\n",
    "# test_x = np.append(test_x_pos, test_x_neg, axis=0)\n",
    "\n",
    "# test_y_pos = np.ones((test_x_pos.shape[0]), dtype=int)\n",
    "\n",
    "# test_y_neg = np.zeros((test_x_neg.shape[0]), dtype=int)\n",
    "# test_y = np.append(test_y_pos, test_y_neg, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdd7a3d8-cecd-4b98-af2c-bddf104ddb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = CustomDataGen(test_files, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8d181ea-1005-433c-a777-047e9dbe38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data_y = []\n",
    "for f in test_files:\n",
    "    label = f.split('/')[-2]\n",
    "    num_label = 0\n",
    "    if label == 'positive':\n",
    "        num_label = 1\n",
    "    hot_enc_label = np.zeros(2)\n",
    "    hot_enc_label[num_label] = 1\n",
    "    test_data_y.append(hot_enc_label)\n",
    "    image = np.load(f)\n",
    "    image = cv2.resize(image, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "    image.reshape(128, 128, 1)\n",
    "    test_data.append(image)\n",
    "test_data = np.array(test_data)\n",
    "test_data_y = np.array(test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f35527b-340a-49e5-a19d-06a141b4341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd7f1d77-4bed-4f6c-a77a-b151be83a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for idx, p in enumerate(predictions):\n",
    "    p_largest = p.argmax()\n",
    "    pred = np.zeros(2)\n",
    "    pred[p_largest] = 1\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "391bac6e-99b3-4dea-ab04-1bb84e9f9196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.]),\n",
       " array([0., 1.]),\n",
       " array([1., 0.]),\n",
       " array([1., 0.])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6138e-c756-4caa-862d-c354cdb8da14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
