{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dae5123-2010-47f4-b44c-a7e7de0b4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import float32\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import Augmentor\n",
    "from pathlib import Path\n",
    "import astropy.stats\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "sys.path.append(os.path.join(Path.cwd(), 'utils'))\n",
    "\n",
    "from utils.im_utils import *\n",
    "from utils.resnet_model import *\n",
    "from utils.simple_conv_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4536e209-ac28-4772-860d-7188b3baaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7f8eaf-4c5e-4958-a533-b2ea475cd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLARE_CLASS = 'M'\n",
    "\n",
    "TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_data/train'\n",
    "VAL_DATA_DIR = f'./data/{FLARE_CLASS}_data/val'\n",
    "TEST_DATA_DIR = f'./data/{FLARE_CLASS}_data/test'\n",
    "\n",
    "AUG_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/train'\n",
    "AUG_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/val'\n",
    "AUG_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/test'\n",
    "\n",
    "AUG_PAIR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented_pair/train'\n",
    "AUG_PAIR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented_pair/val'\n",
    "AUG_PAIR_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented_pair/test'\n",
    "\n",
    "# PAIR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_full_image_data/train'\n",
    "# PAIR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_full_image_data/val'\n",
    "# PAIR_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_full_image_data/test'\n",
    "\n",
    "# AUG_PAIR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_full_image_data_augmented/train'\n",
    "# AUG_PAIR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_full_image_data_augmented/val'\n",
    "# AUG_PAIR_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_full_image_data_augmented/test'\n",
    "\n",
    "RESNET_CHECKPOINTS_DIR = './checkpoints/resnet_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0159f28-d7ff-4a2b-8c68-d9523b0097cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c998e73-948d-471b-9f49-2fbeed37e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train_data():\n",
    "    delete_files(f'{AUG_TRAIN_DATA_DIR}/positive')\n",
    "    delete_files(f'{AUG_TRAIN_DATA_DIR}/negative')\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(TRAIN_DATA_DIR):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            img = np.load(filepath)\n",
    "            # rotated_imgs = [rotate_img(img, 90), rotate_img(img, 180), rotate_img(img, 270)]\n",
    "            # for idx, rot_img in enumerate(rotated_imgs):\n",
    "            #     rotated_img_save = os.path.join(subdir, f'{file}_{idx}_rot')\n",
    "            #     np.save(rotated_img_save, rot_img)\n",
    "\n",
    "            fliplr_img = np.fliplr(img)\n",
    "            flipud_img = np.flipud(img)\n",
    "            rot90_img = np.rot90(img)\n",
    "            rot180_img = np.rot90(img, 2)\n",
    "            rot270_img = np.rot90(img, 3)\n",
    "            \n",
    "            folder = subdir.rsplit('/', 1)[1]\n",
    "            cut_filename = file.rsplit('.', 1)[0]\n",
    "\n",
    "            original_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', cut_filename)\n",
    "            fliplr_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', f'{cut_filename}_fliplr')\n",
    "            flipud_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', f'{cut_filename}_flipud')\n",
    "            rot90_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', f'{cut_filename}_rot90')\n",
    "            rot180_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', f'{cut_filename}_rot180')\n",
    "            rot270_img_save = os.path.join(f'{AUG_TRAIN_DATA_DIR}/{folder}', f'{cut_filename}_rot270')\n",
    "\n",
    "            np.save(original_img_save, img)\n",
    "            np.save(fliplr_img_save, fliplr_img)\n",
    "            np.save(flipud_img_save, flipud_img)\n",
    "            np.save(rot90_img_save, rot90_img)\n",
    "            np.save(rot180_img_save, rot180_img)\n",
    "            np.save(rot270_img_save, rot270_img)\n",
    "\n",
    "            # translated_img = translate(img)\n",
    "            # translated_img_save = os.path.join(subdir, f'{file}_trans')\n",
    "            # np.save(translated_img_save, translated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbcc42c-eb39-4e88-ac3a-87d15fdd96d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pair_train_data(data_category):\n",
    "    data_path = f'{PAIR_TRAIN_DATA_DIR}/{data_category}'\n",
    "    aug_data_path = f'{AUG_PAIR_TRAIN_DATA_DIR}/{data_category}'\n",
    "    delete_files(aug_data_path)\n",
    "    # delete_files(f'{AUG_TRAIN_DATA_DIR}/negative')\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            file_folder = filepath.rsplit('/')[-2]\n",
    "            original_img_sequence_folder_path = f'{aug_data_path}/{file_folder}'\n",
    "            fliplr_img_sequence_folder_path = f'{aug_data_path}/{file_folder}_fliplr'\n",
    "            flipud_img_sequence_folder_path = f'{aug_data_path}/{file_folder}_flipud'\n",
    "            rot90_img_sequence_folder_path = f'{aug_data_path}/{file_folder}_rot90'\n",
    "            rot180_img_sequence_folder_path = f'{aug_data_path}/{file_folder}_rot180'\n",
    "            rot270_img_sequence_folder_path = f'{aug_data_path}/{file_folder}_rot270'\n",
    "            \n",
    "            if not os.path.exists(original_img_sequence_folder_path):\n",
    "                os.makedirs(original_img_sequence_folder_path)\n",
    "            if not os.path.exists(fliplr_img_sequence_folder_path):\n",
    "                os.makedirs(fliplr_img_sequence_folder_path)\n",
    "            if not os.path.exists(flipud_img_sequence_folder_path):\n",
    "                os.makedirs(flipud_img_sequence_folder_path)\n",
    "            if not os.path.exists(rot90_img_sequence_folder_path):\n",
    "                os.makedirs(rot90_img_sequence_folder_path)\n",
    "            if not os.path.exists(rot180_img_sequence_folder_path):\n",
    "                os.makedirs(rot180_img_sequence_folder_path)\n",
    "            if not os.path.exists(rot270_img_sequence_folder_path):\n",
    "                os.makedirs(rot270_img_sequence_folder_path)\n",
    "            \n",
    "            img = np.load(filepath)\n",
    "            fliplr_img = np.fliplr(img)\n",
    "            flipud_img = np.flipud(img)\n",
    "            rot90_img = np.rot90(img)\n",
    "            rot180_img = np.rot90(img, 2)\n",
    "            rot270_img = np.rot90(img, 3)\n",
    "            cut_filename = file.rsplit('.', 1)[0]\n",
    "            \n",
    "            original_img_save = os.path.join(original_img_sequence_folder_path, cut_filename)\n",
    "            fliplr_img_save = os.path.join(fliplr_img_sequence_folder_path, f'{cut_filename}')\n",
    "            flipud_img_save = os.path.join(flipud_img_sequence_folder_path, f'{cut_filename}')\n",
    "            rot90_img_save = os.path.join(rot90_img_sequence_folder_path, f'{cut_filename}')\n",
    "            rot180_img_save = os.path.join(rot180_img_sequence_folder_path, f'{cut_filename}')\n",
    "            rot270_img_save = os.path.join(rot270_img_sequence_folder_path, f'{cut_filename}')\n",
    "\n",
    "            np.save(original_img_save, img)\n",
    "            np.save(fliplr_img_save, fliplr_img)\n",
    "            np.save(flipud_img_save, flipud_img)\n",
    "            np.save(rot90_img_save, rot90_img)\n",
    "            np.save(rot180_img_save, rot180_img)\n",
    "            np.save(rot270_img_save, rot270_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012799a2-6a76-472d-b131-d87d9c6e4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2097f4bb-e782-4449-8bd6-cd8400ce1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment_pair_train_data('positive')\n",
    "# augment_pair_train_data('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff21e7b-856d-4a2f-93e6-d7eeb6044a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_clip(image, mul=3):\n",
    "    scs = astropy.stats.sigma_clipped_stats(image)\n",
    "    sd = scs[2]\n",
    "    thr = sd*mul\n",
    "    image[image<thr] = 0\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d3de72-ac1d-4d80-8324-4c24520ab76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_paths,\n",
    "                 batch_size,\n",
    "                 input_size=(64, 64, 1),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.files_paths = files_paths.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.n = len(self.files_paths)\n",
    "        self.n_category = 2\n",
    "        # self.n_name = df[y_col['name']].nunique()\n",
    "        # self.n_type = df[y_col['type']].nunique()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.files_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.files_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        # image = preprocessing.normalize(np.load(path))\n",
    "        image = np.load(path)\n",
    "        image = np.expand_dims(image, axis=2)\n",
    "        # image = NormalizeData(image)\n",
    "        image = cv2.resize(image, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "        scs = astropy.stats.sigma_clipped_stats(image)\n",
    "        # sd = scs[2]\n",
    "        # thr = sd*5\n",
    "        image[image<0] = 0\n",
    "        # image = preprocessing.normalize(image)\n",
    "        return image\n",
    "\n",
    "    def __get_output(self, path, num_classes=2):\n",
    "        label = None\n",
    "        folder = path.rsplit('/')[-2]\n",
    "        if folder == 'positive':\n",
    "            label = 1\n",
    "        elif folder == 'negative':\n",
    "            label = 0\n",
    "        \n",
    "        return label\n",
    "        # return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "        # path_batch = batches[self.X_col['path']]\n",
    "        # category_batch = batches[self.y_col['type']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in batches])\n",
    "        y_batch = np.asarray([self.__get_output(y, self.n_category) for y in batches])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e279c807-8cc8-433f-a32c-9fc278ce81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPairDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, folder_paths,\n",
    "                 batch_size,\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.folder_paths = folder_paths.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.n = len(self.folder_paths)\n",
    "        self.n_category = 2\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.folder_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.folder_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)  \n",
    "        X = np.expand_dims(X, axis=4)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    \n",
    "    def __get_input(self, folder):\n",
    "        images = []\n",
    "        for subdir, dirs, files in os.walk(folder):\n",
    "            for f in files:\n",
    "                images.append(os.path.join(subdir, f.decode(encoding='UTF-8')))\n",
    "        images = sorted(images)\n",
    "        images = [np.load(x) for x in images]\n",
    "        if len(images) != 2:\n",
    "            print(folder)\n",
    "        images = [cv2.resize(x, (128, 128), interpolation = cv2.INTER_AREA) for x in images]\n",
    "        images = [sigma_clip(x) for x in images]\n",
    "        images  = np.array(images)\n",
    "        return images\n",
    "\n",
    "    def __get_output(self, path, num_classes=2):\n",
    "        label = None\n",
    "        folder = path.rsplit('/')[-2]\n",
    "        if folder == 'positive':\n",
    "            label = 1\n",
    "        elif folder == 'negative':\n",
    "            label = 0\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in batches])\n",
    "        y_batch = np.asarray([self.__get_output(y, self.n_category) for y in batches])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57df7307-f1fa-44db-b3be-19567b1eb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataPaths(train_data_dir, val_data_dir, test_data_dir):\n",
    "    train_files = []\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "         for f in files:\n",
    "            train_files.append(os.path.join(subdir, f))\n",
    "    train_files = np.array(train_files)\n",
    "\n",
    "    val_files = []\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "         for f in files:\n",
    "            val_files.append(os.path.join(subdir, f))\n",
    "    val_files = np.array(val_files)\n",
    "\n",
    "    test_files = []\n",
    "    for subdir, dirs, files in os.walk(test_data_dir):\n",
    "         for f in files:\n",
    "            test_files.append(os.path.join(subdir, f))\n",
    "    test_files = np.array(test_files)\n",
    "    \n",
    "    return train_files, val_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc9e1672-739c-42ee-823a-90705d9e5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataFolders(train_data_dir, val_data_dir, test_data_dir):\n",
    "    train_folders = []\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "        for d in dirs:\n",
    "            if d != 'positive' and d != 'negative' and d != '.ipynb_checkpoints':\n",
    "                train_folders.append(os.path.join(subdir, d))\n",
    "    train_folders = np.array(train_folders)\n",
    "\n",
    "    val_folders = []\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "         for d in dirs:\n",
    "                if d != 'positive' and d != 'negative' and d != '.ipynb_checkpoints':\n",
    "                    val_folders.append(os.path.join(subdir, d))\n",
    "    val_folders = np.array(val_folders)\n",
    "\n",
    "    test_folders = []\n",
    "    for subdir, dirs, files in os.walk(test_data_dir):\n",
    "         for d in dirs:\n",
    "                if d != 'positive' and d != 'negative' and d != '.ipynb_checkpoints':\n",
    "                    test_folders.append(os.path.join(subdir, d))\n",
    "    test_folders = np.array(test_folders)\n",
    "    \n",
    "    return train_folders, val_folders, test_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30188f5b-cfd0-41c7-865f-dfba43bcfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_conv_model():\n",
    "    inp = Input(shape=(64, 64, 1))\n",
    "    x = Conv2D(filters=48, kernel_size=4)(inp)\n",
    "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "    x = Conv2D(filters=24, kernel_size=3)(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "    x = Conv2D(filters=12, kernel_size=3)(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, x)\n",
    "    adam_fine = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=adam_fine, metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b980ff9-7dad-463b-8c77-455f9f763242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomAlexNet1():\n",
    "    inp = Input(shape=(128, 128, 1))\n",
    "    x = Conv2D(filters=96, kernel_size=(11, 11), activation='relu')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(pool_size=(3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(filters=256, kernel_size=(5, 5), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(pool_size=(3, 3))(x)\n",
    "    \n",
    "    x = Conv2D(filters=384, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(filters=384, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = MaxPool2D(pool_size=(3, 3))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be3d504-382a-4021-8d2e-bd827be643c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomPairAlexNet():\n",
    "    inp = Input(shape=(2, 128, 128, 1))\n",
    "    cutout_inp = tf.convert_to_tensor([inp[x][0] for x in range(256)])\n",
    "    full_inp = tf.convert_to_tensor([inp[x][1] for x in range(256)])\n",
    "    print(cutout_inp.shape)\n",
    "    print(full_inp.shape)\n",
    "    # full_inp = Input(shape=(128, 128, 1))\n",
    "    \n",
    "    cutout_features = CustomAlexNet1()(cutout_inp)\n",
    "    full_features = CustomAlexNet1()(full_inp)\n",
    "    \n",
    "    x = concatenate([cutout_features, full_features])\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a25bdd8d-14fe-41b1-8f84-3ee921ea1e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 10:10:50.385055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:50.902944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:50.905275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:50.906942: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-15 10:10:51.056268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:51.057507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:51.058731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:55.384223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:55.385522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:55.386778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22307 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-08-15 10:10:55.387163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 10:10:55.387671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10490 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:4b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 128, 128, 1)\n",
      "(256, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# model = CustomAlexNet1()\n",
    "model = CustomPairAlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca277cbf-d923-4a31-9b2b-2bc803b98e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs=30\n",
    "train_files, val_files, test_files = GetDataFolders(AUG_PAIR_TRAIN_DATA_DIR, AUG_PAIR_VAL_DATA_DIR, AUG_PAIR_TEST_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "183bb673-3202-4c7f-8eb5-b1813fa18418",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = CustomPairDataGen(train_files, batch_size)\n",
    "valgen = CustomPairDataGen(val_files, batch_size)\n",
    "\n",
    "val_x = np.concatenate([valgen[x][0] for x in range(len(valgen)+1)])\n",
    "val_y = np.concatenate([valgen[x][1] for x in range(len(valgen)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10645801-18b7-4424-8c90-2ce35ccc12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "182/182 [==============================] - 177s 950ms/step - loss: 0.8873 - accuracy: 0.7335 - val_loss: 4.8535 - val_accuracy: 0.5273\n",
      "Epoch 2/30\n",
      "182/182 [==============================] - 169s 927ms/step - loss: 0.3671 - accuracy: 0.8564 - val_loss: 0.4098 - val_accuracy: 0.8281\n",
      "Epoch 3/30\n",
      "182/182 [==============================] - 168s 920ms/step - loss: 0.2824 - accuracy: 0.8918 - val_loss: 0.7493 - val_accuracy: 0.7852\n",
      "Epoch 4/30\n",
      "182/182 [==============================] - 168s 921ms/step - loss: 0.1558 - accuracy: 0.9371 - val_loss: 1.1133 - val_accuracy: 0.7812\n",
      "Epoch 5/30\n",
      "182/182 [==============================] - 168s 919ms/step - loss: 0.0368 - accuracy: 0.9879 - val_loss: 1.8501 - val_accuracy: 0.7383\n",
      "Epoch 6/30\n",
      "182/182 [==============================] - 168s 920ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 1.5211 - val_accuracy: 0.8320\n",
      "Epoch 7/30\n",
      "182/182 [==============================] - 168s 922ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 1.5468 - val_accuracy: 0.8164\n",
      "Epoch 8/30\n",
      "182/182 [==============================] - 168s 921ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 2.2580 - val_accuracy: 0.7188\n",
      "Epoch 9/30\n",
      "182/182 [==============================] - 168s 922ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.1631 - val_accuracy: 0.8438\n",
      "Epoch 10/30\n",
      "182/182 [==============================] - 169s 926ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 1.8113 - val_accuracy: 0.8008\n",
      "Epoch 11/30\n",
      "182/182 [==============================] - 168s 922ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 1.9006 - val_accuracy: 0.7578\n",
      "Epoch 12/30\n",
      "182/182 [==============================] - 168s 921ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.4400 - val_accuracy: 0.7422\n",
      "Epoch 13/30\n",
      "182/182 [==============================] - 169s 924ms/step - loss: 5.4042e-04 - accuracy: 0.9999 - val_loss: 2.0002 - val_accuracy: 0.7930\n",
      "Epoch 14/30\n",
      "182/182 [==============================] - 168s 921ms/step - loss: 7.6229e-05 - accuracy: 1.0000 - val_loss: 3.0822 - val_accuracy: 0.7539\n",
      "Epoch 15/30\n",
      "182/182 [==============================] - 169s 924ms/step - loss: 3.7517e-05 - accuracy: 1.0000 - val_loss: 2.7775 - val_accuracy: 0.7617\n",
      "Epoch 16/30\n",
      "182/182 [==============================] - 168s 921ms/step - loss: 3.5914e-05 - accuracy: 1.0000 - val_loss: 2.9795 - val_accuracy: 0.7734\n",
      "Epoch 17/30\n",
      "182/182 [==============================] - 169s 924ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 2.4761 - val_accuracy: 0.8242\n",
      "Epoch 18/30\n",
      "182/182 [==============================] - 168s 920ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 2.9768 - val_accuracy: 0.7148\n",
      "Epoch 19/30\n",
      "182/182 [==============================] - 168s 923ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 2.0534 - val_accuracy: 0.7969\n",
      "Epoch 20/30\n",
      "182/182 [==============================] - 168s 922ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.9479 - val_accuracy: 0.7734\n",
      "Epoch 21/30\n",
      "182/182 [==============================] - 168s 924ms/step - loss: 6.9236e-04 - accuracy: 0.9999 - val_loss: 2.5182 - val_accuracy: 0.7461\n",
      "Epoch 22/30\n",
      "182/182 [==============================] - 168s 923ms/step - loss: 6.3467e-05 - accuracy: 1.0000 - val_loss: 2.0329 - val_accuracy: 0.7891\n",
      "Epoch 23/30\n",
      "182/182 [==============================] - 168s 923ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 2.1739 - val_accuracy: 0.7578\n",
      "Epoch 24/30\n",
      "182/182 [==============================] - 169s 925ms/step - loss: 3.5323e-04 - accuracy: 0.9999 - val_loss: 2.2004 - val_accuracy: 0.7734\n",
      "Epoch 25/30\n",
      "182/182 [==============================] - 168s 923ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.1371 - val_accuracy: 0.6641\n",
      "Epoch 26/30\n",
      "182/182 [==============================] - 167s 918ms/step - loss: 9.6100e-05 - accuracy: 1.0000 - val_loss: 2.7830 - val_accuracy: 0.7266\n",
      "Epoch 27/30\n",
      "182/182 [==============================] - 168s 922ms/step - loss: 1.2524e-04 - accuracy: 1.0000 - val_loss: 2.3953 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "182/182 [==============================] - 169s 927ms/step - loss: 7.0254e-05 - accuracy: 1.0000 - val_loss: 2.5338 - val_accuracy: 0.7422\n",
      "Epoch 29/30\n",
      "182/182 [==============================] - 169s 926ms/step - loss: 2.2431e-05 - accuracy: 1.0000 - val_loss: 3.1876 - val_accuracy: 0.7422\n",
      "Epoch 30/30\n",
      "182/182 [==============================] - 169s 925ms/step - loss: 9.8111e-06 - accuracy: 1.0000 - val_loss: 3.0439 - val_accuracy: 0.7383\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "adam_fine = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam_fine, metrics=[\"accuracy\"])\n",
    "history = model.fit(traingen, validation_data = valgen, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e9ee83a-4f59-49a0-8852-f33073fbcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(f'{RESNET_CHECKPOINTS_DIR}/alexnet_aug_pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "758584c4-cc30-40ce-b5fe-24f55a90913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3418172d00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f'{RESNET_CHECKPOINTS_DIR}/alexnet_aug_pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9d87f-7d7f-4dc7-8519-f76b5f99c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs=30\n",
    "train_files, val_files, test_files = GetDataPaths(AUG_TRAIN_DATA_DIR, AUG_VAL_DATA_DIR, AUG_TEST_DATA_DIR)\n",
    "traingen = CustomDataGen(train_files, batch_size)\n",
    "valgen = CustomDataGen(val_files, batch_size)\n",
    "testgen = CustomDataGen(test_files, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4896b48-7382-450c-981c-68cbe1fa77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = np.concatenate([traingen[x][0] for x in range(len(traingen)+1)])\n",
    "# train_y = np.concatenate([traingen[x][1] for x in range(len(traingen)+1)])\n",
    "\n",
    "val_x = np.concatenate([valgen[x][0] for x in range(len(valgen)+1)])\n",
    "val_y = np.concatenate([valgen[x][1] for x in range(len(valgen)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4351c22-6ee8-45f9-b326-c4d737b8ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "# with mirrored_strategy.scope():\n",
    "#     model = CustomAlexNet()\n",
    "#     adam_fine = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)\n",
    "#     model.compile(loss=\"binary_crossentropy\", optimizer=adam_fine, metrics=[\"accuracy\"])\n",
    "#     history = model.fit(traingen, validation_data = valgen, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b503a-2842-4ed4-9554-f7f90d47c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_simple_conv_model(include_top=True)\n",
    "# model = get_test_conv_model()\n",
    "# model = CustomResNet50(include_top=True)\n",
    "model = CustomAlexNet()\n",
    "adam_fine = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-4,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "    \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam_fine, metrics=[\"accuracy\"])\n",
    "# callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)]\n",
    "# model.summary()\n",
    "history = model.fit(traingen, validation_data = (val_x, val_y), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4677a59-4c6d-4c12-bd24-36ab88e7cbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 2, 128, 128, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3eb0b76d-7e90-4f93-9f46-13fb1c9037d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51b6f0ef-cdfa-40dc-b4a9-25c0912b3eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 785ms/step\n",
      "accuracy: 0.4140625\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(valgen)\n",
    "true_vals = val_y[:256]\n",
    "\n",
    "correct = 0\n",
    "for idx, pred in enumerate(predictions):\n",
    "    pred_round = 0\n",
    "    if pred >= 0.5:\n",
    "        pred_round = 1\n",
    "    if pred_round == true_vals[idx]:\n",
    "        correct += 1\n",
    "\n",
    "print(f'accuracy: {correct/(len(true_vals))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d192ce5c-bc3e-47c3-adb7-54f26081a99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 2, 128, 128, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ba32c1b-3e49-4f60-8841-4e80e48cf024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f107a6d-31fc-4067-873c-52dc6c1d9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb7c5a-edd2-409f-acbe-24f933029ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(f'{RESNET_CHECKPOINTS_DIR}/simple_conv_custom_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22805ddd-eb29-4dac-9f5b-3d99fe1e6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'{RESNET_CHECKPOINTS_DIR}/simple_conv_relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd12fa16-baa0-4e20-889d-3b5e955389bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "adam_fine = Adam(learning_rate=0.00005, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1c8f8-bb94-404a-b613-e1513d1c0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomResNet50(include_top=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(traingen, validation_data = valgen, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6ccfb-0a09-4176-9fd4-11a0675d510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'{RESNET_CHECKPOINTS_DIR}/sgd_newdata_B_class_1e-3_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ccdb5-2eab-47a1-be6d-f8f5a9655a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.load('./data/B_data/train/positive/AIA20160107_0354_0094_0.npy')\n",
    "t = cv2.resize(t, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "t = np.array([t.reshape(128, 128, 1)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a10844-9a83-466b-8048-5fce4054e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68825b8-ba01-47a2-aed6-53f8772fa784",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799941a-c143-4b89-a9d2-23bb7a953a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
