{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dae5123-2010-47f4-b44c-a7e7de0b4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import float32\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4536e209-ac28-4772-860d-7188b3baaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da7f8eaf-4c5e-4958-a533-b2ea475cd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = './data/train'\n",
    "VAL_DATA_DIR = './data/val'\n",
    "TEST_DATA_DIR = './data/test'\n",
    "\n",
    "AUG_TRAIN_DATA_DIR = './data_augmented/train'\n",
    "AUG_VAL_DATA_DIR = './data_augmented/val'\n",
    "AUG_TEST_DATA_DIR = './data_augmented/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c998e73-948d-471b-9f49-2fbeed37e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(AUG_TRAIN_DATA_DIR):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(subdir, file)\n",
    "        img = np.load(filepath)\n",
    "        # rotated_imgs = [rotate_img(img, 90), rotate_img(img, 180), rotate_img(img, 270)]\n",
    "        # for idx, rot_img in enumerate(rotated_imgs):\n",
    "        #     rotated_img_save = os.path.join(subdir, f'{file}_{idx}_rot')\n",
    "        #     np.save(rotated_img_save, rot_img)\n",
    "            \n",
    "        fliplr_img = np.fliplr(img)\n",
    "        flipud_img = np.flipud(img)\n",
    "        \n",
    "        fliplr_img_save = os.path.join(subdir, f'{file}_fliplr')\n",
    "        flipud_img_save = os.path.join(subdir, f'{file}_flipud')\n",
    "        \n",
    "        np.save(fliplr_img_save, fliplr_img)\n",
    "        np.save(flipud_img_save, flipud_img)\n",
    "        \n",
    "        # translated_img = translate(img)\n",
    "        # translated_img_save = os.path.join(subdir, f'{file}_trans')\n",
    "        # np.save(translated_img_save, translated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46d3de72-ac1d-4d80-8324-4c24520ab76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_paths,\n",
    "                 batch_size,\n",
    "                 input_size=(128, 128, 1),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.files_paths = files_paths.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.n = len(self.files_paths)\n",
    "        self.n_category = 2\n",
    "        # self.n_name = df[y_col['name']].nunique()\n",
    "        # self.n_type = df[y_col['type']].nunique()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.files_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.files_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        image = np.load(path)\n",
    "        image = cv2.resize(image, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "        return image\n",
    "\n",
    "    def __get_output(self, path, num_classes=2):\n",
    "        label = None\n",
    "        folder = path.rsplit('/')[-2]\n",
    "        if folder == 'positive':\n",
    "            label = 1\n",
    "        elif folder == 'negative':\n",
    "            label = 0\n",
    "        return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "        # path_batch = batches[self.X_col['path']]\n",
    "        # category_batch = batches[self.y_col['type']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in batches])\n",
    "        y_batch = np.asarray([self.__get_output(y, self.n_category) for y in batches])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96deae2f-d7af-44f7-8083-2f2a20a1f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "  \n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3411fa5-775b-478b-9c01-a6b2970f4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "   \n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4bf297fe-1860-4847-b4da-d2e0e78a304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(include_top=True, weights=None,\n",
    "             input_tensor=None, input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=2):\n",
    "    \"\"\"Instantiates the ResNet50 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    #if weights == 'imagenet' and include_top and classes != 15:\n",
    "    #    raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "    #                     ' as true, `classes` should be 15')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    \n",
    "    # input_shape = _obtain_input_shape(input_shape,\n",
    "    #                                   default_size=256,\n",
    "    #                                   min_size=197,\n",
    "    #                                   data_format=K.image_data_format(),\n",
    "    #                                   require_flatten=include_top)\n",
    "    \n",
    "    input_shape = (128, 128, 1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "            \n",
    "    print(K.image_data_format())\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = AveragePooling2D((4, 4), name='avg_pool')(x)\n",
    "\n",
    "#     # x = Flatten()(x)\n",
    "#     # x = Dense(1, activation='sigmoid', name='fc2')(x)\n",
    "    \n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(2, activation='softmax', name='fc2')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    # x = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "57df7307-f1fa-44db-b3be-19567b1eb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for subdir, dirs, files in os.walk(AUG_TRAIN_DATA_DIR):\n",
    "     for f in files:\n",
    "        train_files.append(os.path.join(subdir, f))\n",
    "train_files = np.array(train_files)\n",
    "\n",
    "val_files = []\n",
    "for subdir, dirs, files in os.walk(AUG_VAL_DATA_DIR):\n",
    "     for f in files:\n",
    "        val_files.append(os.path.join(subdir, f))\n",
    "val_files = np.array(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b9e66987-a91a-4acc-a16d-430dd21578a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "for subdir, dirs, files in os.walk(AUG_TEST_DATA_DIR):\n",
    "     for f in files:\n",
    "        test_files.append(os.path.join(subdir, f))\n",
    "test_files = np.array(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "45a3bff6-9026-4cc9-8bfa-4ee28c42a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.load('./data_augmented/train/negative/AIA20100712_0436_0094.npy_flipud.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0ed9d87f-7d7f-4dc7-8519-f76b5f99c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = CustomDataGen(train_files, 64)\n",
    "valgen = CustomDataGen(val_files, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bd12fa16-baa0-4e20-889d-3b5e955389bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "model = ResNet50(include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17f1c8f8-bb94-404a-b613-e1513d1c0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - 17s 143ms/step - loss: 1.1221 - accuracy: 0.5923 - val_loss: 1.4234 - val_accuracy: 0.5208\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.7494 - accuracy: 0.5038 - val_loss: 0.8945 - val_accuracy: 0.5208\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 11s 140ms/step - loss: 0.7246 - accuracy: 0.5214 - val_loss: 0.7273 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.7044 - accuracy: 0.5284 - val_loss: 0.7095 - val_accuracy: 0.5260\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.7052 - accuracy: 0.5433 - val_loss: 0.7070 - val_accuracy: 0.4896\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6994 - accuracy: 0.5319 - val_loss: 1.8357 - val_accuracy: 0.5104\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.7013 - accuracy: 0.5294 - val_loss: 0.7508 - val_accuracy: 0.4896\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6990 - accuracy: 0.5539 - val_loss: 0.8580 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6903 - accuracy: 0.5545 - val_loss: 0.6800 - val_accuracy: 0.5260\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.7085 - accuracy: 0.5537 - val_loss: 0.8090 - val_accuracy: 0.5104\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.7005 - accuracy: 0.5445 - val_loss: 0.7176 - val_accuracy: 0.5729\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6872 - accuracy: 0.5671 - val_loss: 0.6986 - val_accuracy: 0.5208\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6862 - accuracy: 0.5613 - val_loss: 0.7645 - val_accuracy: 0.5417\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6822 - accuracy: 0.5655 - val_loss: 0.7417 - val_accuracy: 0.5052\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.7085 - accuracy: 0.5455 - val_loss: 0.7285 - val_accuracy: 0.4792\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6926 - accuracy: 0.5609 - val_loss: 0.6881 - val_accuracy: 0.5365\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6826 - accuracy: 0.5733 - val_loss: 0.7193 - val_accuracy: 0.5365\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.6856 - accuracy: 0.5839 - val_loss: 0.7614 - val_accuracy: 0.5052\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6794 - accuracy: 0.5761 - val_loss: 0.7520 - val_accuracy: 0.5156\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6766 - accuracy: 0.5976 - val_loss: 0.7026 - val_accuracy: 0.5104\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.6828 - accuracy: 0.5645 - val_loss: 0.6990 - val_accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.6756 - accuracy: 0.5841 - val_loss: 0.6934 - val_accuracy: 0.5573\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6897 - accuracy: 0.5837 - val_loss: 0.7021 - val_accuracy: 0.5156\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6990 - accuracy: 0.5567 - val_loss: 0.7092 - val_accuracy: 0.5208\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6941 - accuracy: 0.5905 - val_loss: 0.7369 - val_accuracy: 0.4948\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6796 - accuracy: 0.5847 - val_loss: 0.7131 - val_accuracy: 0.4948\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.6746 - accuracy: 0.5946 - val_loss: 0.7261 - val_accuracy: 0.4844\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6668 - accuracy: 0.5942 - val_loss: 0.6806 - val_accuracy: 0.5625\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6962 - accuracy: 0.5857 - val_loss: 0.7129 - val_accuracy: 0.5521\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6735 - accuracy: 0.5931 - val_loss: 0.8196 - val_accuracy: 0.5208\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6821 - accuracy: 0.5891 - val_loss: 0.7387 - val_accuracy: 0.5104\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.6770 - accuracy: 0.5982 - val_loss: 0.8970 - val_accuracy: 0.5052\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6659 - accuracy: 0.5988 - val_loss: 0.7100 - val_accuracy: 0.5208\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6618 - accuracy: 0.6128 - val_loss: 1.7204 - val_accuracy: 0.5208\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6672 - accuracy: 0.6110 - val_loss: 0.7194 - val_accuracy: 0.5521\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6736 - accuracy: 0.6184 - val_loss: 0.8080 - val_accuracy: 0.4844\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6698 - accuracy: 0.6050 - val_loss: 0.7132 - val_accuracy: 0.5781\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.6618 - accuracy: 0.6134 - val_loss: 0.7084 - val_accuracy: 0.5469\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6566 - accuracy: 0.6162 - val_loss: 0.7059 - val_accuracy: 0.5573\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6487 - accuracy: 0.6276 - val_loss: 0.8084 - val_accuracy: 0.5677\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6512 - accuracy: 0.6294 - val_loss: 0.7589 - val_accuracy: 0.5052\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6455 - accuracy: 0.6334 - val_loss: 1.4246 - val_accuracy: 0.5573\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6416 - accuracy: 0.6422 - val_loss: 0.7492 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6300 - accuracy: 0.6522 - val_loss: 0.7810 - val_accuracy: 0.4844\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6209 - accuracy: 0.6603 - val_loss: 0.8446 - val_accuracy: 0.5156\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.6151 - accuracy: 0.6681 - val_loss: 0.7325 - val_accuracy: 0.5521\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.6009 - accuracy: 0.6733 - val_loss: 0.7359 - val_accuracy: 0.5677\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.5906 - accuracy: 0.6961 - val_loss: 0.7319 - val_accuracy: 0.5208\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.5668 - accuracy: 0.7075 - val_loss: 0.7981 - val_accuracy: 0.5365\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.5555 - accuracy: 0.7196 - val_loss: 1.2543 - val_accuracy: 0.4896\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.5357 - accuracy: 0.7342 - val_loss: 0.8397 - val_accuracy: 0.5156\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.5224 - accuracy: 0.7422 - val_loss: 0.8246 - val_accuracy: 0.5417\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.5077 - accuracy: 0.7588 - val_loss: 1.0763 - val_accuracy: 0.4948\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.4880 - accuracy: 0.7662 - val_loss: 0.8945 - val_accuracy: 0.4948\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.4535 - accuracy: 0.7857 - val_loss: 0.9157 - val_accuracy: 0.5365\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.4020 - accuracy: 0.8177 - val_loss: 0.9974 - val_accuracy: 0.5104\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.3813 - accuracy: 0.8293 - val_loss: 1.1295 - val_accuracy: 0.5469\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.3542 - accuracy: 0.8478 - val_loss: 1.3077 - val_accuracy: 0.5573\n",
      "Epoch 59/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.3256 - accuracy: 0.8638 - val_loss: 1.2310 - val_accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.3075 - accuracy: 0.8740 - val_loss: 1.4500 - val_accuracy: 0.5208\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.2807 - accuracy: 0.8808 - val_loss: 1.3573 - val_accuracy: 0.5208\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.2372 - accuracy: 0.9032 - val_loss: 1.4146 - val_accuracy: 0.5208\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.2268 - accuracy: 0.9060 - val_loss: 1.5828 - val_accuracy: 0.5417\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.2132 - accuracy: 0.9191 - val_loss: 1.2773 - val_accuracy: 0.5625\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.1741 - accuracy: 0.9325 - val_loss: 1.5980 - val_accuracy: 0.5156\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.1424 - accuracy: 0.9459 - val_loss: 1.6901 - val_accuracy: 0.5417\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.1510 - accuracy: 0.9435 - val_loss: 1.4363 - val_accuracy: 0.5208\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.1459 - accuracy: 0.9473 - val_loss: 1.8666 - val_accuracy: 0.5052\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.1317 - accuracy: 0.9509 - val_loss: 1.7836 - val_accuracy: 0.5365\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1168 - accuracy: 0.9541 - val_loss: 1.8241 - val_accuracy: 0.5208\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1014 - accuracy: 0.9655 - val_loss: 2.8336 - val_accuracy: 0.4896\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1087 - accuracy: 0.9611 - val_loss: 1.7816 - val_accuracy: 0.5365\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.1133 - accuracy: 0.9559 - val_loss: 1.7692 - val_accuracy: 0.5365\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0904 - accuracy: 0.9712 - val_loss: 2.2120 - val_accuracy: 0.5104\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0772 - accuracy: 0.9722 - val_loss: 2.1373 - val_accuracy: 0.5208\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0729 - accuracy: 0.9746 - val_loss: 2.3825 - val_accuracy: 0.5208\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.0793 - accuracy: 0.9724 - val_loss: 2.2707 - val_accuracy: 0.5156\n",
      "Epoch 78/100\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 0.1047 - accuracy: 0.9655 - val_loss: 2.6543 - val_accuracy: 0.5104\n",
      "Epoch 79/100\n",
      "39/78 [==============>...............] - ETA: 5s - loss: 0.0642 - accuracy: 0.9776"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [123]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(traingen, validation_data = valgen, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593785c-312e-4a93-b529-2cfc5c955a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x_pos = get_data_array(f'{TEST_DATA_DIR}/positive')\n",
    "# test_x_neg = get_data_array(f'{TEST_DATA_DIR}/negative')\n",
    "# test_x = np.append(test_x_pos, test_x_neg, axis=0)\n",
    "\n",
    "# test_y_pos = np.ones((test_x_pos.shape[0]), dtype=int)\n",
    "\n",
    "# test_y_neg = np.zeros((test_x_neg.shape[0]), dtype=int)\n",
    "# test_y = np.append(test_y_pos, test_y_neg, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d181ea-1005-433c-a777-047e9dbe38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data_y = []\n",
    "for f in test_files:\n",
    "    label = f.split('/')[-2]\n",
    "    num_label = 0\n",
    "    if label == 'positive':\n",
    "        num_label = 1\n",
    "    hot_enc_label = np.zeros(2)\n",
    "    hot_enc_label[num_label] = 1\n",
    "    test_data_y.append(hot_enc_label)\n",
    "    image = np.load(f)\n",
    "    image = cv2.resize(image, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "    image.reshape(128, 128, 1)\n",
    "    test_data.append(image)\n",
    "test_data = np.array(test_data)\n",
    "test_data_y = np.array(test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35527b-340a-49e5-a19d-06a141b4341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f1d77-4bed-4f6c-a77a-b151be83a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for idx, p in enumerate(predictions):\n",
    "    p_largest = p.argmax()\n",
    "    pred = np.zeros(2)\n",
    "    pred[p_largest] = 1\n",
    "    preds.append(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
