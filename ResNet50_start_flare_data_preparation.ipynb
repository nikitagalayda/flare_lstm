{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bca0536-9b58-4bdf-8324-f4e73528d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sunpy.map\n",
    "from sunpy.time import parse_time\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3feb98fe-b71a-4f0e-8262-1192c1ec4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa998fa6-ff3a-4739-af71-936e8b559035",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIA_DATA_DIR = '../../MVTS_data_preparation/data'\n",
    "EVENTS_BY_DATE_DIR = './new_events_by_date'\n",
    "EVENTS_BY_CLASS_DIR = './new_events_by_class'\n",
    "\n",
    "TRAIN_DATA_POSITIVE_DIR = './data_all_classes/train/positive'\n",
    "TRAIN_DATA_NEGATIVE_DIR = './data_all_classes/train/negative'\n",
    "TEST_DATA_POSITIVE_DIR = './data_all_classes/test/positive'\n",
    "TEST_DATA_NEGATIVE_DIR = './data_all_classes/test/negative'\n",
    "VAL_DATA_POSITIVE_DIR = './data_all_classes/val/positive'\n",
    "VAL_DATA_NEGATIVE_DIR = './data_all_classes/val/negative'\n",
    "\n",
    "LSTM_TRAIN_DATA_POSITIVE_DIR = './lstm_data/train/positive'\n",
    "LSTM_TRAIN_DATA_NEGATIVE_DIR = './lstm_data/train/negative'\n",
    "LSTM_TEST_DATA_POSITIVE_DIR = './lstm_data/test/positive'\n",
    "LSTM_TEST_DATA_NEGATIVE_DIR = './lstm_data/test/negative'\n",
    "LSTM_VAL_DATA_POSITIVE_DIR = './lstm_data/val/positive'\n",
    "LSTM_VAL_DATA_NEGATIVE_DIR = './lstm_data/val/negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a8dba5-c70d-4ba6-8360-e714efacdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CDELT = 0.599733;\n",
    "HPCCENTER = 4096.0 / 2.0;\n",
    "rsun_meters = 696000;\n",
    "dsun_meters = 149600000;\n",
    "DEFAULT_WIDTH, DEFAULT_HEIGHT = 64, 64\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec4f53d-afbe-4345-8528-225b5c1ec0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614945d0-242f-4dee-9d5e-ba76fdda240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data():\n",
    "    delete_files(TRAIN_DATA_POSITIVE_DIR)\n",
    "    delete_files(TRAIN_DATA_NEGATIVE_DIR)\n",
    "    delete_files(TEST_DATA_POSITIVE_DIR)\n",
    "    delete_files(TEST_DATA_NEGATIVE_DIR)\n",
    "    delete_files(VAL_DATA_POSITIVE_DIR)\n",
    "    delete_files(VAL_DATA_NEGATIVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9497b771-1008-4ad0-ab9f-830e52d74ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_lstm_data():\n",
    "    delete_files(LSTM_TRAIN_DATA_POSITIVE_DIR)\n",
    "    delete_files(LSTM_TRAIN_DATA_NEGATIVE_DIR)\n",
    "    delete_files(LSTM_TEST_DATA_POSITIVE_DIR)\n",
    "    delete_files(LSTM_TEST_DATA_NEGATIVE_DIR)\n",
    "    delete_files(LSTM_VAL_DATA_POSITIVE_DIR)\n",
    "    delete_files(LSTM_VAL_DATA_NEGATIVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2679576e-00bd-41c0-b166-c02d84c79121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAIAFormatFilename(dt):\n",
    "    AIA_data_date = f'{dt.year}{dt.month:02d}{dt.day:02d}'\n",
    "    AIA_data_time = f'{dt.hour:02d}{dt.minute:02d}'\n",
    "    AIA_data_filename = f'AIA{AIA_data_date}_{AIA_data_time}_0094'\n",
    "    \n",
    "    return AIA_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3f3284-f780-4ee3-910d-3ea5d527eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a formatted file name of the closest AIA data file to the given datetime\n",
    "\n",
    "def GetClosestDataFileByDate(dt, rounding):\n",
    "    AIA_data_date = f'{dt.year}{dt.month:02d}{dt.day:02d}'\n",
    "    tmp_dt = dt\n",
    "    minute = 0\n",
    "    \n",
    "    if(rounding == \"down\"):\n",
    "        minute = GetClosestMultipleDown(tmp_dt.minute, 6)\n",
    "    elif(rounding == \"up\"):\n",
    "        minute = GetClosestMultipleUp(tmp_dt.minute, 6)\n",
    "    \n",
    "    if(minute == 60):\n",
    "        tmp_dt = tmp_dt + datetime.timedelta(hours=1)\n",
    "        minute = 0\n",
    "    \n",
    "    AIA_data_time = f'{tmp_dt.hour:02d}{minute:02d}'\n",
    "    AIA_data_filename = f'AIA{AIA_data_date}_{AIA_data_time}_0094.npz'\n",
    "    \n",
    "    return AIA_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b40db44-68bd-452f-9e7b-43c97ccd768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an NxN cutout of an AIA image array centered around the given coordinate\n",
    "\n",
    "def GetCutout(im, coord, N=64):\n",
    "    x_end_idx = int(coord[0]+N)\n",
    "    y_end_idx = int(coord[1]+N)\n",
    "    cutout_array = im[int(coord[0]):x_end_idx, int(coord[1]):y_end_idx]\n",
    "    \n",
    "    return cutout_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed19cb9-2a54-4041-9d38-d6f33624bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an NxN cutout of a file centered around the given coordinate\n",
    "\n",
    "def GetFileCutout(path, coord, N=64):\n",
    "    im = np.load(path)['x']\n",
    "    \n",
    "    return GetCutout(im, coord, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4529c69-de72-4dba-b80a-c9d091e16e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an AIA filepath closest to the provided\n",
    "\n",
    "def GetAIAPathAtTime(dt):\n",
    "    dt_data_dir = os.path.join(AIA_DATA_DIR, f'{dt.year}/{dt.month:02d}/{dt.day:02d}')\n",
    "    closest_data_file = GetClosestDataFileByDate(dt, \"up\")\n",
    "    file_path = os.path.join(dt_data_dir, closest_data_file)\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0847ac90-0c55-4bf7-933a-071152537177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# returns M consecutive (forward or backward) AIA filepaths starting at time closest to the given time\n",
    "\n",
    "def GetAIANCutoutsPaths(start_dt, direction='backward', M=6, cadence=6):\n",
    "    cutouts_paths = []\n",
    "    if direction == 'backward':\n",
    "        cadence = -cadence\n",
    "    dynamic_dt = start_dt\n",
    "        \n",
    "    for i in range(M):\n",
    "        try:\n",
    "            cutout_path = GetAIAPathAtTime(dynamic_dt)\n",
    "        except FileNotFoundError:\n",
    "            dynamic_dt = dynamic_dt + datetime.timedelta(minutes=cadence)\n",
    "            continue\n",
    "        cutouts_paths.append(cutout_path)\n",
    "        dynamic_dt = dynamic_dt + datetime.timedelta(minutes=cadence)\n",
    "    \n",
    "    cutouts_paths = sorted(cutouts_paths)\n",
    "    num_paths = len(cutouts_paths)\n",
    "    filled_paths = cutouts_paths\n",
    "\n",
    "    if num_paths != M:\n",
    "        # print(f'filling files, start_dt: {start_dt} num_paths: {num_paths} len filled_paths: {len(filled_paths)}')\n",
    "        diff = abs(M-num_paths)\n",
    "        # print(f'diff: {diff} num-diff: {num_paths-diff}')\n",
    "        for i in range(num_paths, num_paths-diff, -1):\n",
    "            filled_paths.insert(i-1, filled_paths[i-1])\n",
    "            # print(f'inserted {filled_paths[i-1]} at pos {i-1}')\n",
    "        filled_paths = sorted(filled_paths)\n",
    "        # print(f'after filling: {np.array(filled_paths)}')\n",
    "    filled_paths = sorted(filled_paths)\n",
    "    return np.array(filled_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2929b5a-f5c4-4eab-b2a8-0198df8947a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves directional sequences of NxN cutouts of all events in the csv file to folders with start times as names\n",
    "\n",
    "def SaveAIANCutoutsFromDF(df, save_dir, time_delta, num_frames=1, direction='backward', flare_class='all'):\n",
    "    nonexistent = 0\n",
    "    for index, row in df.iterrows():\n",
    "        raw_time, goes_cls = parse_time(row['event_starttime'], precision=0), row['fl_goescls'][0]\n",
    "        if flare_class != 'all':\n",
    "            if goes_cls != flare_class:\n",
    "                continue\n",
    "        start_dt, y, x = raw_time.datetime, int(row['hpc_x']), int(row['hpc_y'])\n",
    "        prior_dt = start_dt + datetime.timedelta(minutes=time_delta)\n",
    "        coord = ConvertHPCToPixXY((x, y))\n",
    "        coord = ResizeCoord(coord)\n",
    "        coord = (coord[0]-32, 512-coord[1]-32)\n",
    "        \n",
    "        closest_file_name = GetClosestDataFileByDate(prior_dt, rounding='up')\n",
    "        closest_file_path = f'{AIA_DATA_DIR}/{prior_dt.year}/{prior_dt.month:02}/{prior_dt.day:02}/{closest_file_name}'\n",
    "\n",
    "        if not os.path.exists(closest_file_path):\n",
    "            nonexistent+=1\n",
    "            continue\n",
    "        \n",
    "        paths = GetAIANCutoutsPaths(prior_dt, direction=direction, M=num_frames, cadence=6)\n",
    "        if len(paths) != num_frames:\n",
    "            print(start_dt)\n",
    "            print(len(paths))\n",
    "        mod_save_dir = save_dir\n",
    "        \n",
    "        if len(paths) == 0:\n",
    "            print('0 paths')\n",
    "            continue\n",
    "        \n",
    "        if len(paths) > 1:\n",
    "            folder_name = GetAIAFormatFilename(start_dt)\n",
    "            event_folder_path = os.path.join(save_dir, folder_name)\n",
    "            if not os.path.exists(event_folder_path):\n",
    "                os.makedirs(event_folder_path)\n",
    "            else:\n",
    "                print(f'trying to create existing folder, time: {start_dt}')\n",
    "                continue \n",
    "            mod_save_dir = event_folder_path\n",
    "        for idx, p in enumerate(paths):\n",
    "            cutout = GetFileCutout(p, coord)\n",
    "            save_filename = os.path.basename(p).rsplit('.', 1)[0]\n",
    "            np.save(f'{mod_save_dir}/{save_filename}_{idx}', cutout)\n",
    "    # print(f'{nonexistent} files did not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed42af3f-a704-480a-af7c-6c4170a7ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateResnetData(test_split=0.25, val_split=0.15, classes='all'):\n",
    "    delete_data()\n",
    "    train_split = 1-test_split+val_split\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(EVENTS_BY_CLASS_DIR):\n",
    "        for file in files:\n",
    "            if classes != 'all':\n",
    "                if file.rsplit('.', 1)[0] != classes:\n",
    "                    continue\n",
    "            print(file.rsplit('.', 1)[0])\n",
    "            class_df = pd.read_csv(os.path.join(subdir, file))\n",
    "            CreateResnetDataOfClass(class_df, test_split, val_split, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ad92ff2-1778-42af-8bc5-b6deda2545e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLSTMData(test_split=0.1, val_split=0.1, classes='all'):\n",
    "    delete_lstm_data()\n",
    "    train_split = 1-test_split+val_split\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(EVENTS_BY_CLASS_DIR):\n",
    "        for file in files:\n",
    "            if classes != 'all':\n",
    "                if file.rsplit('.', 1)[0] != classes:\n",
    "                    continue\n",
    "            print(file.rsplit('.', 1)[0])\n",
    "            class_df = pd.read_csv(os.path.join(subdir, file))\n",
    "            CreateLSTMDataOfClass(class_df, test_split, val_split, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f0e038-779c-4246-971b-d66468092f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateResnetDataOfClass(class_df, test_split, val_split, classes='all'):\n",
    "    class_df = class_df.sample(frac=1).reset_index(drop=True)\n",
    "    event_num = len(class_df)\n",
    "    test_split_num, val_split_num = math.ceil(event_num*test_split), math.ceil(event_num*val_split)\n",
    "    test_df = class_df[-test_split_num:]\n",
    "    class_df = class_df[:-test_split_num]\n",
    "    val_df = class_df[-val_split_num:]\n",
    "    class_df = class_df[:-val_split_num]\n",
    "    time_delta = 0\n",
    "    random_time_delta = -36\n",
    "    \n",
    "    SaveAIANCutoutsFromDF(test_df, TEST_DATA_POSITIVE_DIR, time_delta, num_frames=1, direction='forward', flare_class=classes)\n",
    "    SaveAIANCutoutsFromDF(test_df, TEST_DATA_NEGATIVE_DIR, random_time_delta, num_frames=1, direction='backward', flare_class=classes)\n",
    "    \n",
    "    SaveAIANCutoutsFromDF(val_df, VAL_DATA_POSITIVE_DIR, time_delta, num_frames=1, direction='forward', flare_class=classes)\n",
    "    SaveAIANCutoutsFromDF(val_df, VAL_DATA_NEGATIVE_DIR, random_time_delta, num_frames=1, direction='backward', flare_class=classes)\n",
    "    \n",
    "    SaveAIANCutoutsFromDF(class_df, TRAIN_DATA_POSITIVE_DIR, time_delta, num_frames=1, direction='forward', flare_class=classes)\n",
    "    SaveAIANCutoutsFromDF(class_df, TRAIN_DATA_NEGATIVE_DIR, random_time_delta, num_frames=1, direction='backward', flare_class=classes)\n",
    "    \n",
    "    # print(f'total training data: {len(train_df)*2}, total val data: {len(val_df)*2}, total test data: {len(test_df)*2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77401e82-5685-4736-aa92-fcd5cd56399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLSTMDataOfClass(class_df, test_split, val_split, classes='all'):\n",
    "    class_df = class_df.sample(frac=1).reset_index(drop=True)\n",
    "    event_num = len(class_df)\n",
    "    test_split_num, val_split_num = math.ceil(event_num*test_split), math.ceil(event_num*val_split)\n",
    "    test_df = class_df[-test_split_num:]\n",
    "    class_df = class_df[:-test_split_num]\n",
    "    val_df = class_df[-val_split_num:]\n",
    "    class_df = class_df[:-val_split_num]\n",
    "    time_delta = -6\n",
    "    random_mult = np.random.randint(3, 7)\n",
    "    random_time_delta = random_mult * time_delta\n",
    "    \n",
    "    SaveAIANCutoutsFromDF(test_df, LSTM_TEST_DATA_POSITIVE_DIR, time_delta, num_frames=6, direction='backward', flare_class=classes)\n",
    "    SaveAIANCutoutsFromDF(test_df, LSTM_TEST_DATA_NEGATIVE_DIR, random_time_delta, num_frames=6, direction='backward', flare_class=classes)\n",
    "    \n",
    "    SaveAIANCutoutsFromDF(val_df, LSTM_VAL_DATA_POSITIVE_DIR, time_delta, num_frames=6, direction='backward', flare_class=classes)\n",
    "    SaveAIANCutoutsFromDF(val_df, LSTM_VAL_DATA_NEGATIVE_DIR, random_time_delta, num_frames=6, direction='backward', flare_class=classes)\n",
    "    \n",
    "    SaveAIANCutoutsFromDF(class_df, LSTM_TRAIN_DATA_POSITIVE_DIR, time_delta, num_frames=6, direction='backward', flare_class=classes)\n",
    "    SaveAIANCutoutsFromDF(class_df, LSTM_TRAIN_DATA_NEGATIVE_DIR, random_time_delta, num_frames=6, direction='backward', flare_class=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07dd4569-6276-4875-bcc3-187db000bd88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "A\n",
      "M\n",
      "B\n",
      "X\n",
      "B-checkpoint\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCreateResnetData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mCreateResnetData\u001b[0;34m(test_split, val_split, classes)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(file\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     11\u001b[0m class_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subdir, file))\n\u001b[0;32m---> 12\u001b[0m \u001b[43mCreateResnetDataOfClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mCreateResnetDataOfClass\u001b[0;34m(class_df, test_split, val_split, classes)\u001b[0m\n\u001b[1;32m     10\u001b[0m random_time_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m36\u001b[39m\n\u001b[1;32m     12\u001b[0m SaveAIANCutoutsFromDF(test_df, TEST_DATA_POSITIVE_DIR, time_delta, num_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, flare_class\u001b[38;5;241m=\u001b[39mclasses)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mSaveAIANCutoutsFromDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_DATA_NEGATIVE_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_time_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflare_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m SaveAIANCutoutsFromDF(val_df, VAL_DATA_POSITIVE_DIR, time_delta, num_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, flare_class\u001b[38;5;241m=\u001b[39mclasses)\n\u001b[1;32m     16\u001b[0m SaveAIANCutoutsFromDF(val_df, VAL_DATA_NEGATIVE_DIR, random_time_delta, num_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m, flare_class\u001b[38;5;241m=\u001b[39mclasses)\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mSaveAIANCutoutsFromDF\u001b[0;34m(df, save_dir, time_delta, num_frames, direction, flare_class)\u001b[0m\n\u001b[1;32m     41\u001b[0m     mod_save_dir \u001b[38;5;241m=\u001b[39m event_folder_path\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(paths):\n\u001b[0;32m---> 43\u001b[0m     cutout \u001b[38;5;241m=\u001b[39m \u001b[43mGetFileCutout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     save_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(p)\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     45\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmod_save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, cutout)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mGetFileCutout\u001b[0;34m(path, coord, N)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGetFileCutout\u001b[39m(path, coord, N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GetCutout(im, coord, N)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/numpy/lib/npyio.py:243\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/numpy/lib/format.py:778\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    777\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 778\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    780\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/numpy/lib/format.py:907\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 907\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/zipfile.py:924\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 924\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/zipfile.py:1000\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[1;32m    999\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m-> 1000\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CreateResnetData(classes='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927fc9ca-641f-485e-9eca-773ea0932f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CreateLSTMData(classes='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf926f36-0eca-4927-bace-556445d04d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_data = 0\n",
    "total_test_data = 0\n",
    "total_val_data = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(TRAIN_DATA_POSITIVE_DIR):\n",
    "    total_train_data += len(files)\n",
    "    \n",
    "for subdir, dirs, files in os.walk(TRAIN_DATA_NEGATIVE_DIR):\n",
    "    total_train_data += len(files)\n",
    "    \n",
    "for subdir, dirs, files in os.walk(TEST_DATA_POSITIVE_DIR):\n",
    "    total_test_data += len(files)\n",
    "    \n",
    "for subdir, dirs, files in os.walk(TEST_DATA_NEGATIVE_DIR):\n",
    "    total_test_data += len(files)\n",
    "    \n",
    "for subdir, dirs, files in os.walk(VAL_DATA_POSITIVE_DIR):\n",
    "    total_val_data += len(files)\n",
    "    \n",
    "for subdir, dirs, files in os.walk(VAL_DATA_NEGATIVE_DIR):\n",
    "    total_val_data += len(files)\n",
    "    \n",
    "print(f'train data: {total_train_data} val data: {total_val_data} test data: {total_test_data}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
