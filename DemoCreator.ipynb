{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c50284a-d5a7-4e3b-8e9d-b59d0f23a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sunpy.time import parse_time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFont\n",
    "from matplotlib import cm\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "sys.path.append(os.path.join(Path.cwd(), 'utils'))\n",
    "sys.path.append(os.path.join(Path.cwd(), 'models'))\n",
    "\n",
    "from utils.region_detector import *\n",
    "from utils.im_utils import *\n",
    "from utils.data_augmentation import *\n",
    "from models.bidirectional_convlstm_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b425998-3921-405d-afe8-d6eaf7c4a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29265589-06cc-44a0-9980-eb126ad7bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a formatted file name of the closest AIA data file to the given datetime\n",
    "\n",
    "def GetClosestDataFileByDate(dt):\n",
    "    AIA_data_date = f'{dt.year}{dt.month:02d}{dt.day:02d}'\n",
    "    tmp_dt = dt\n",
    "    minute = 0\n",
    "    minute=GetClosestMultiple(tmp_dt.minute, 6)\n",
    "    AIA_data_time = f'{tmp_dt.hour:02d}{minute:02d}'\n",
    "    AIA_data_filename = f'AIA{AIA_data_date}_{AIA_data_time}_0094.npz'\n",
    "    \n",
    "    return AIA_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442901b1-dc8f-4224-a0c2-74d1b299221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveMaxValsForClass(flare_class):\n",
    "    class_df = pd.read_csv(f'./event_records/new_events_by_class/{flare_class}.csv')\n",
    "    max_vals = []\n",
    "    \n",
    "    for index, row in class_df.iterrows():\n",
    "        event_peaktime = parse_time(row['event_peaktime']).datetime\n",
    "        closest_file = GetClosestDataFileByDate(event_peaktime)\n",
    "        closest_filepath = f'../data_94/{event_peaktime.year}/{event_peaktime.month:02}/{event_peaktime.day:02}/{closest_file}'\n",
    "        try:\n",
    "            closest_image = np.load(closest_filepath)['x']\n",
    "            max_vals.append(closest_image.max())\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "            \n",
    "    df = pd.DataFrame(max_vals, columns = ['val'])\n",
    "    df.to_csv(f'./{flare_class}_max_vals.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3e7b09-d790-41cd-ab7c-ec12b2357fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data_94'\n",
    "VIDEOS_DIR = './videos'\n",
    "FRAMES_DIR = './frames'\n",
    "FRAMES_MARKED_DIR = './frames/frames_marked'\n",
    "CUTOUT_FRAMES_MARKED = './frames/cutout_frames_marked/'\n",
    "LSTM_CHECKPOINTS_DIR = './checkpoints/lstm_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcac2804-be07-4e1e-b4b0-08c74ce62c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e979bdab-d8d6-4ee0-9671-e8bb9fcf9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a formatted file name of the closest AIA data file to the given datetime\n",
    "\n",
    "def GetClosestDataFileByDate(dt):\n",
    "    AIA_data_date = f'{dt.year}{dt.month:02d}{dt.day:02d}'\n",
    "    tmp_dt = dt\n",
    "    minute = 0\n",
    "    minute=GetClosestMultiple(tmp_dt.minute, 6)\n",
    "    AIA_data_time = f'{tmp_dt.hour:02d}{minute:02d}'\n",
    "    AIA_data_filename = f'AIA{AIA_data_date}_{AIA_data_time}_0094.npz'\n",
    "    \n",
    "    return AIA_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe5b572-c694-4c36-8217-030fa8312ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAIAPathAtTime(dt):\n",
    "    dt_data_dir = os.path.join(DATA_DIR, f'{dt.year}/{dt.month:02d}/{dt.day:02d}')\n",
    "    closest_data_file = GetClosestDataFileByDate(dt)\n",
    "    file_path = os.path.join(dt_data_dir, closest_data_file)\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError\n",
    "    \n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a288b8-8e6b-4299-acc8-8dff089b2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFilepathsBetweenDates(start_datetime, end_datetime, cadence=6):\n",
    "    filepaths = []\n",
    "    loop_date = start_datetime\n",
    "    \n",
    "    while(loop_date < end_datetime):\n",
    "        closest_filepath = None\n",
    "        try:\n",
    "            closest_filepath = GetAIAPathAtTime(loop_date)\n",
    "        except(FileNotFoundError):\n",
    "            loop_date = loop_date + datetime.timedelta(minutes=cadence)\n",
    "            continue\n",
    "        filepaths.append(closest_filepath)\n",
    "        loop_date = loop_date + datetime.timedelta(minutes=cadence)\n",
    "    \n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8615c274-8bbe-4942-bd00-669665279fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_func(x):\n",
    "    return int(x.split('.')[-2].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d313ee-ecd2-404e-a152-ba259530431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteImages(filepaths):\n",
    "    frames = [Image.fromarray(np.uint8(np.load(x)['x'])) for x in filepaths]\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame.save(f'{FRAMES_DIR}/{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c4ed9c-e9a7-409a-927e-c40a6caba7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCleanAIAFilename(filename):\n",
    "    return filename.rsplit('/', 1)[-1].rsplit('.', 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6db6bac-8590-4420-9fcb-089ae86bd8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PosToClass(pos):\n",
    "    # depth = len(flare_classes)\n",
    "    # return tf.one_hot(pos, depth)\n",
    "    if pos == 0:\n",
    "        return 'N'\n",
    "    elif pos == 1:\n",
    "        return 'C'\n",
    "    elif pos == 2:\n",
    "        return 'M'\n",
    "    elif pos == 3:\n",
    "        return 'X'\n",
    "    else:\n",
    "        return 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e866c1ea-ee6f-43c5-89b3-a144dec331af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImageCutouts(image, cutout_size=64, stride=16):\n",
    "    width, height = image.shape[0] , image.shape[1]\n",
    "    h_pass, v_pass = height//cutout_size, width//cutout_size\n",
    "    cutouts = []\n",
    "    for i in range(0, height-cutout_size, stride):\n",
    "        for j in range(0, width-cutout_size, stride):\n",
    "            cutouts.append(image[i:i+cutout_size, j:j+cutout_size])\n",
    "    \n",
    "    return np.array(cutouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fdf855b8-cb45-4882-8baf-260265fea0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WritePredictedCutouts(save_dir, filepaths, full_disk_model, cutout_model, flare_classes, image_size=64, sequence_length=5, stride=32):\n",
    "    delete_files(save_dir)\n",
    "    images_raw = [np.load(x)['x'] for x in filepaths]\n",
    "    images_raw_diff = [abs(images_raw[x]-images_raw[x-1]) for x in range(1, len(images_raw))]\n",
    "    images = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw]\n",
    "    images_diff = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw_diff]\n",
    "    in_flaring_period = False\n",
    "    # coords for the center of the flare\n",
    "    flare_coords = None\n",
    "    flare_class = 0\n",
    "    base_logfile_name = f'./logs/flare_detections/cutout_model'\n",
    "    month_logfile = open(f'{base_logfile_name}.txt', 'w')\n",
    "    all_flare_coords = None\n",
    "    \n",
    "    for i in range(sequence_length, len(images_raw_diff)):\n",
    "        past_images = images_diff[i-sequence_length:i]\n",
    "        past_images = np.array(past_images)\n",
    "        past_images = np.expand_dims(past_images, 0)\n",
    "        past_images = np.expand_dims(past_images, 4)\n",
    "        # print(past_images.shape)\n",
    "        # now the shape is 1, 12, 64, 64, 1 of full sun images\n",
    "        prediction = full_disk_model.predict(past_images, verbose=0)\n",
    "        pos = prediction[0].argmax()\n",
    "        past_images_pil = [Image.fromarray(x).convert(\"RGBA\") for x in np.uint8(images_raw[i-sequence_length:i])]\n",
    "        past_images_raw = images_raw[i-sequence_length:i]\n",
    "        first_image_pil = past_images_pil[0]\n",
    "        draw = ImageDraw.Draw(first_image_pil)\n",
    "            \n",
    "        if pos > 0:\n",
    "            if not in_flaring_period:\n",
    "                in_flaring_period = True\n",
    "                past_images_raw_diff = images_raw_diff[i-sequence_length:i]\n",
    "                # past_images_cutouts = np.array([GetImageCutouts(x, 64, stride) for x in past_images_raw_diff])\n",
    "                # shape = 5, N, 64, 64\n",
    "                # past_images_cutouts = np.array([past_images_cutouts[:, x] for x in range(past_images_cutouts.shape[1])])\n",
    "                # print(past_images_cutouts.shape)\n",
    "                # return past_images_cutouts\n",
    "                # shape = N, 5, 64, 64\n",
    "                predictions = []\n",
    "                # for cutout_sequence in past_images_cutouts:\n",
    "                #     cutout_sequence_merged = np.concatenate([np.expand_dims(cutout_sequence, 0), past_images[:, :, :, :, 0]], axis=1)\n",
    "                #     predictions.append(cutout_model.predict(cutout_sequence_merged, verbose=0))\n",
    "                    \n",
    "                top_regions_coords = GetImageTopNRegionsCoords(past_images_raw_diff[-1], N=1)\n",
    "                top_region_cutouts = np.array(\n",
    "                    [[GetSafeCenteredCutout(im, 64, x) for x in top_regions_coords] for im in past_images_raw]\n",
    "                )\n",
    "                top_region_cutouts = np.array([top_region_cutouts[:, x] for x in range(top_region_cutouts.shape[1])])\n",
    "                \n",
    "                # return top_region_cutouts\n",
    "                \n",
    "                top_regions_coords = [[x[1], x[0]] for x in top_regions_coords]\n",
    "                \n",
    "                for region_cutout in top_region_cutouts:\n",
    "                    cutouts = np.expand_dims(region_cutout, 0)\n",
    "                    # cutouts = np.expand_dims(cutouts, 4)\n",
    "                    # shape = 1, 5, 64, 64, 1\n",
    "                    cutout_sequence_merged = np.concatenate([cutouts, past_images[:, :, :, :, 0]], axis=1)\n",
    "                    cutout_sequence_merged = np.expand_dims(cutout_sequence_merged, 4)\n",
    "                    predictions.append(cutout_model.predict(cutout_sequence_merged, verbose=0))\n",
    "                top_region_prediction_classes = np.array([x.argmax() for x in predictions])\n",
    "                #now only uses the first flare region aka [2 1 0] -> returns index 0 for only the first flare\n",
    "                flare_cutout_indeces = np.where(top_region_prediction_classes > 0)[0]\n",
    "                if len(flare_cutout_indeces) == 0:\n",
    "                    continue\n",
    "                flare_cutout_index = flare_cutout_indeces[0]\n",
    "                flare_coords = top_regions_coords[flare_cutout_index]\n",
    "                flare_class = top_region_prediction_classes[flare_cutout_index]\n",
    "                \n",
    "                month_logfile.write(f'from: {GetCleanAIAFilename(filepaths[i-sequence_length])} to: {GetCleanAIAFilename(filepaths[i+1])}\\n')\n",
    "                month_logfile.write(str(predictions)+'\\n')\n",
    "                month_logfile.write(str(predictions[flare_cutout_index])+'\\n')\n",
    "                month_logfile.write(str(top_regions_coords)+'\\n')\n",
    "                month_logfile.write(str(flare_coords)+'\\n')\n",
    "                month_logfile.write(str(flare_classes[flare_class])+'\\n')\n",
    "                month_logfile.write('--------------------------------------------------------------------------------------\\n')\n",
    "                \n",
    "                # for idx, c in enumerate(past_images_cutouts):\n",
    "                    # cutouts = np.expand_dims(c, 0)\n",
    "                    # cutouts = np.expand_dims(cutouts, 4)\n",
    "                    # # shape = 1, 5, 64, 64, 1\n",
    "                    # predictions.append(cutout_model.predict(cutouts, verbose=0))\n",
    "                # predictions = np.array(predictions)\n",
    "                # predicted_classes = np.array([x.argmax() for x in predictions])\n",
    "                # flare_cutout_indeces = np.where(predicted_classes > 0)[0]\n",
    "                # all_flare_coords = [(x/(512/stride)*stride, x%(512/stride)*stride) for x in flare_cutout_indeces]\n",
    "                # print(all_flare_coords)\n",
    "                \n",
    "                # for coord in flare_coords:\n",
    "                tl, br = (flare_coords[0]-32, flare_coords[1]-32), (flare_coords[0]+32, flare_coords[1]+32)\n",
    "                draw = ImageDraw.Draw(first_image_pil)\n",
    "                draw.rectangle((tl, br), outline=\"red\")\n",
    "#                 max_predictions = np.array([predictions[x].max() for x in flare_cutout_indeces])\n",
    "#                 max_predictions_index = max_predictions.argmax()\n",
    "#                 max_pred_index = flare_cutout_indeces[max_predictions_index]\n",
    "                \n",
    "#                 flare_center_coords = (max_pred_index/(512/stride)*stride, max_pred_index%(512/stride)*stride)\n",
    "#                 flare_coords = flare_center_coords\n",
    "            # for coord in flare_coords:\n",
    "            tl, br = (flare_coords[0]-32, flare_coords[1]-32), (flare_coords[0]+32, flare_coords[1]+32)\n",
    "            draw = ImageDraw.Draw(first_image_pil)\n",
    "            draw.rectangle((tl, br), outline=\"red\")\n",
    "            # tl, br = (flare_coords[0]-32, flare_coords[1]-32), (flare_coords[0]+32, flare_coords[1]+32)\n",
    "            # draw = ImageDraw.Draw(first_image_pil)\n",
    "            # draw.rectangle((tl, br), outline=\"red\")\n",
    "            \n",
    "        elif pos == 0:\n",
    "            in_flaring_period = False\n",
    "            flare_coords = None\n",
    "            flare_class = 0\n",
    "            all_flare_coords = None\n",
    "            \n",
    "        filename = filepaths[i-sequence_length].rsplit('/')[-1].rsplit('.', 1)[0]\n",
    "        draw.text((12, 490),filename,(255,255,255))\n",
    "        draw.text((400, 490), flare_classes[flare_class], (255,255,255))\n",
    "        first_image_pil.save(f'{save_dir}/{i-sequence_length}.png', \"PNG\")\n",
    "        \n",
    "    month_logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d0fd27b-9b6b-484e-99fc-2ddb98b64edd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TestWritePredictedCutouts(save_dir, filepaths, full_disk_model, cutout_model, flare_classes, image_size=64, sequence_length=5, stride=32):\n",
    "    delete_files(save_dir)\n",
    "    images_raw = [np.load(x)['x'] for x in filepaths]\n",
    "    images_raw_diff = [abs(images_raw[x]-images_raw[x-1]) for x in range(1, len(images_raw))]\n",
    "    images = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw]\n",
    "    images_diff = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw_diff]\n",
    "    in_flaring_period = False\n",
    "    # coords for the center of the flare\n",
    "    flare_coords = None\n",
    "    flare_class = 0\n",
    "    base_logfile_name = f'./logs/flare_detections/cutout_model'\n",
    "    month_logfile = open(f'{base_logfile_name}.txt', 'w')\n",
    "    all_flare_coords = None\n",
    "    \n",
    "    for i in range(sequence_length, len(images_raw_diff)):\n",
    "        past_images = images_diff[i-sequence_length:i]\n",
    "        past_images = np.array(past_images)\n",
    "        past_images = np.expand_dims(past_images, 0)\n",
    "        past_images = np.expand_dims(past_images, 4)\n",
    "        # print(past_images.shape)\n",
    "        # now the shape is 1, 12, 64, 64, 1 of full sun images\n",
    "        prediction = full_disk_model.predict(past_images, verbose=0)\n",
    "        pos = prediction[0].argmax()\n",
    "        past_images_pil = [Image.fromarray(x).convert(\"RGBA\") for x in np.uint8(images_raw[i-sequence_length:i])]\n",
    "        past_images_raw = images_raw[i-sequence_length:i]\n",
    "        first_image_pil = past_images_pil[0]\n",
    "        draw = ImageDraw.Draw(first_image_pil)\n",
    "            \n",
    "        if pos > 0:\n",
    "            if not in_flaring_period:\n",
    "                in_flaring_period = True\n",
    "                past_images_raw_diff = images_raw_diff[i-sequence_length:i]\n",
    "                past_images_cutouts = np.array([GetImageCutouts(x, 64, stride) for x in past_images_raw_diff])\n",
    "                # shape = 5, N, 64, 64\n",
    "                past_images_cutouts = np.array([past_images_cutouts[:, x] for x in range(past_images_cutouts.shape[1])])\n",
    "                return past_images, past_images_cutouts\n",
    "                # print(past_images_cutouts.shape)\n",
    "                # return past_images_cutouts\n",
    "                # shape = N, 5, 64, 64\n",
    "                predictions = []\n",
    "                for cutout_sequence in past_images_cutouts:\n",
    "                    cutout_sequence_merged = np.concatenate([past_images[:, :, :, :, 0], np.expand_dims(cutout_sequence, 0)], axis=1)\n",
    "                    predictions.append(cutout_model.predict(np.expand_dims(cutout_sequence_merged, 4), verbose=0))\n",
    "                    \n",
    "                # month_logfile.write(f'from: {GetCleanAIAFilename(filepaths[i-sequence_length])} to: {GetCleanAIAFilename(filepaths[i+1])}\\n')\n",
    "                # month_logfile.write(str(predictions)+'\\n')\n",
    "                # month_logfile.write(str(predictions[flare_cutout_index])+'\\n')\n",
    "                # month_logfile.write(str(top_regions_coords)+'\\n')\n",
    "                # month_logfile.write(str(flare_coords)+'\\n')\n",
    "                # month_logfile.write(str(flare_classes[flare_class])+'\\n')\n",
    "                # month_logfile.write('--------------------------------------------------------------------------------------\\n')\n",
    "                \n",
    "                # for idx, c in enumerate(past_images_cutouts):\n",
    "                #     cutouts = np.expand_dims(c, 0)\n",
    "                #     cutouts = np.expand_dims(cutouts, 4)\n",
    "                #     # shape = 1, 5, 64, 64, 1\n",
    "                #     predictions.append(cutout_model.predict(cutouts, verbose=0))\n",
    "                predictions = np.array(predictions)\n",
    "                predicted_classes = np.array([x.argmax() for x in predictions])\n",
    "                flare_cutout_indeces = np.where(predicted_classes > 0)[0]\n",
    "                flare_coords = [(x/(512/stride)*stride, x%(512/stride)*stride) for x in flare_cutout_indeces]\n",
    "                \n",
    "            for coord in flare_coords:\n",
    "                tl, br = (coord[0]-32, coord[1]-32), (coord[0]+32, coord[1]+32)\n",
    "                draw = ImageDraw.Draw(first_image_pil)\n",
    "                draw.rectangle((tl, br), outline=\"red\")\n",
    "            \n",
    "        elif pos == 0:\n",
    "            in_flaring_period = False\n",
    "            flare_coords = None\n",
    "            flare_class = 0\n",
    "            all_flare_coords = None\n",
    "            \n",
    "        filename = filepaths[i-sequence_length].rsplit('/')[-1].rsplit('.', 1)[0]\n",
    "        draw.text((12, 490),filename,(255,255,255))\n",
    "        draw.text((400, 490), flare_classes[flare_class], (255,255,255))\n",
    "        first_image_pil.save(f'{save_dir}/{i-sequence_length}.png', \"PNG\")\n",
    "        \n",
    "    month_logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78189f99-2d0a-4b84-b470-3753b6689264",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WritePredictedImages(save_dir, title, filepaths, model, flare_classes, image_size=64, sequence_length=5, rect_size=64):\n",
    "    delete_files(save_dir)\n",
    "    images_raw = [np.load(x)['x'] for x in filepaths]\n",
    "    images_raw_diff = [abs(images_raw[x]-images_raw[x-1]) for x in range(1, len(images_raw))]\n",
    "    images = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw]\n",
    "    images_diff = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw_diff]\n",
    "    logfile = open(f'./videos/logs/{title}.txt', 'w')\n",
    "    \n",
    "    for i in range(sequence_length, len(images_diff)):\n",
    "        past_images = images_diff[i-sequence_length:i]\n",
    "        past_images = np.array(past_images)\n",
    "        past_images = np.expand_dims(past_images, 0)\n",
    "        past_images = np.expand_dims(past_images, 4)\n",
    "        # now the shape is 1, 12, 64, 64, 1 of full sun images\n",
    "        prediction = model.predict(past_images, verbose=0)\n",
    "        pos = prediction[0].argmax()\n",
    "        # print(f'{prediction} CLASS: {PosToClass(pos)}')\n",
    "        # print('--------------------------------------------------------------------------------------')\n",
    "        past_images_pil = [Image.fromarray(x).convert(\"RGBA\") for x in np.uint8(images_raw[i-sequence_length:i])]\n",
    "        past_images_raw = images_raw[i-sequence_length:i]\n",
    "        first_image_pil = past_images_pil[0]\n",
    "        logfile.write(f'from: {GetCleanAIAFilename(filepaths[i-sequence_length])} to: {GetCleanAIAFilename(filepaths[i+1])}\\n')\n",
    "        logfile.write(str(prediction[0])+'\\n')\n",
    "        logfile.write(str(pos)+'\\n')\n",
    "        logfile.write('--------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "        draw = ImageDraw.Draw(first_image_pil)\n",
    "        if pos > 1:\n",
    "            first_image_raw = past_images_raw[0]\n",
    "            center_coord = GetImageTopNRegionsCoords(first_image_raw, 1)[0]\n",
    "            tl, br = (center_coord[1]-rect_size//2, center_coord[0]-rect_size//2), (center_coord[1]+rect_size//2, center_coord[0]+rect_size//2)\n",
    "            draw.rectangle((tl, br), outline=\"red\")\n",
    "        filename = filepaths[i-sequence_length].rsplit('/')[-1].rsplit('.', 1)[0]\n",
    "        draw.text((12, 490),filename,(255,255,255))\n",
    "        draw.text((400, 490),PosToClass(pos),(255,255,255))\n",
    "        first_image_pil.save(f'{save_dir}/{i-sequence_length}.png', \"PNG\")\n",
    "    logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b66f53d8-6f7d-45f7-a1c5-b8b63814089a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WriteStartEndImages(save_dir, title, filepaths, start_model, end_model, image_size=64, sequence_length=5, rect_size=64):\n",
    "    delete_files(save_dir)\n",
    "    \n",
    "    model = start_model\n",
    "    cur_flare_location = None\n",
    "    cur_flare_class = 'N'\n",
    "    \n",
    "    \n",
    "    images_raw = [np.load(x)['x'] for x in filepaths]\n",
    "    images_raw_diff = [abs(images_raw[x]-images_raw[x-1]) for x in range(1, len(images_raw))]\n",
    "    images = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw]\n",
    "    images_diff = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw_diff]\n",
    "    logfile = open(f'./videos/logs/{title}.txt', 'w')\n",
    "    for i in range(sequence_length, len(images_diff)):\n",
    "        past_images = images_diff[i-sequence_length:i]\n",
    "        past_images = np.array(past_images)\n",
    "        past_images = np.expand_dims(past_images, 0)\n",
    "        past_images = np.expand_dims(past_images, 4)\n",
    "        # now the shape is 1, 12, 64, 64, 1 of full sun images\n",
    "        prediction = model.predict(past_images, verbose=0)\n",
    "        pos = prediction[0].argmax()\n",
    "        cur_flare_class = PosToClasslass(pos)\n",
    "        # print(f'{prediction} CLASS: {PosToClass(pos)}')\n",
    "        # print('--------------------------------------------------------------------------------------')\n",
    "        past_images_pil = [Image.fromarray(x).convert(\"RGBA\") for x in np.uint8(images_raw[i-sequence_length:i])]#[Image.fromarray(np.uint8(images_raw[i-x])).convert(\"RGBA\") for x in range(sequence_length, 0, -1)]\n",
    "        past_images_raw = images_raw[i-sequence_length:i]#[images_raw[i-x] for x in range(sequence_length, 0, -1)]\n",
    "        first_image_pil = past_images_pil[0]\n",
    "        logfile.write(f'from: {GetCleanAIAFilename(filepaths[i-sequence_length])} to: {GetCleanAIAFilename(filepaths[i+1])}\\n')\n",
    "        logfile.write(str(prediction[0])+'\\n')\n",
    "        logfile.write(str(pos)+'\\n')\n",
    "        logfile.write('--------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "        draw = ImageDraw.Draw(first_image_pil)\n",
    "        if model == start_model:\n",
    "            if pos > 0:\n",
    "                # Flare detected\n",
    "                model = end_model\n",
    "                first_image_raw = past_images_raw[0]\n",
    "                cur_flare_location = GetImageTopNRegionsCoords(first_image_raw, 1)[0]\n",
    "                tl, br = (cur_flare_location[1]-rect_size//2, cur_flare_location[0]-rect_size//2), (cur_flare_location[1]+rect_size//2, cur_flare_location[0]+rect_size//2)\n",
    "                draw.rectangle((tl, br), outline=\"red\")\n",
    "        elif model == end_model:\n",
    "            if pos > 0:\n",
    "                cur_flare_location = None\n",
    "                cur_flare_class = 'N'\n",
    "                model = start_model\n",
    "            else:\n",
    "                tl, br = (cur_flare_location[1]-rect_size//2, cur_flare_location[0]-rect_size//2), (cur_flare_location[1]+rect_size//2, cur_flare_location[0]+rect_size//2)\n",
    "                draw.rectangle((tl, br), outline=\"red\")\n",
    "        filename = filepaths[i-sequence_length].rsplit('/')[-1].rsplit('.', 1)[0]\n",
    "        draw.text((12, 490),filename,(255,255,255))\n",
    "        draw.text((400, 490), cur_flare_class, (255,255,255))\n",
    "        first_image_pil.save(f'{save_dir}/{i-sequence_length}.png', \"PNG\")\n",
    "    logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c331abaa-c9d6-4b0d-982f-e8240bde1e5f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetClosestFlareToDatetime(dt):\n",
    "    year_month_flare_df = pd.read_csv(f'./event_records/new_events_by_date/{dt.year}/{dt.month}.csv')\n",
    "    closest_flare = year_month_flare_df.iloc[0]\n",
    "    for index, row in year_month_flare_df.iterrows():\n",
    "        cur_closest_flare_time = parse_time(closest_flare['event_starttime'], precision=0).datetime\n",
    "        row_start_time = parse_time(row['event_starttime'], precision=0).datetime\n",
    "        if abs(dt-row_start_time) < abs(dt-cur_closest_flare_time):\n",
    "            closest_flare = row\n",
    "    \n",
    "    return closest_flare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4462e76-deee-4b02-b697-49f0f5d23edf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CalculateDetectionError(filepaths, start_model, end_model, image_size=64, sequence_length=5):\n",
    "    model = start_model\n",
    "    cur_flare_location = None\n",
    "    closest_flare = None\n",
    "    cur_flare_class = 'N'\n",
    "    start_total_error_time = datetime.timedelta(seconds=0)\n",
    "    end_total_error_time = datetime.timedelta(seconds=0)\n",
    "    predicted_flares = 0\n",
    "    images_raw = [np.load(x)['x'] for x in filepaths]\n",
    "    images_raw_diff = [abs(images_raw[x]-images_raw[x-1]) for x in range(1, len(images_raw))]\n",
    "    images_diff = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw_diff]\n",
    "    predicted_start_time, predicted_end_time = None, None\n",
    "    logfile = open(f'./logs/flare_detections/flare_detections.txt', 'w')\n",
    "    pred_logfile = open(f'./logs/flare_detections/flare_detections_full_log.txt', 'w')\n",
    "    for idx, i in enumerate(range(sequence_length, len(images_diff))):\n",
    "        past_images = images_diff[i-sequence_length:i]\n",
    "        past_images = np.array(past_images)\n",
    "        past_images = np.expand_dims(past_images, 0)\n",
    "        past_images = np.expand_dims(past_images, 4)\n",
    "        # now the shape is 1, 12, 64, 64, 1 of full sun images\n",
    "        prediction = model.predict(past_images, verbose=0)\n",
    "        pos = prediction[0].argmax()\n",
    "        cur_flare_class = PosToClass(pos)\n",
    "        \n",
    "        pred_logfile.write(f'from: {GetCleanAIAFilename(filepaths[i-sequence_length])} to: {GetCleanAIAFilename(filepaths[i+1])}\\n')\n",
    "        pred_logfile.write(str(prediction[0])+'\\n')\n",
    "        pred_logfile.write(str(pos)+'\\n')\n",
    "        pred_logfile.write('--------------------------------------------------------------------------------------\\n')\n",
    "        \n",
    "        if pos > 0:\n",
    "            if model == start_model:\n",
    "                # Flare detected\n",
    "                predicted_start_time = parse_time(filepaths[i-sequence_length].rsplit('.', 1)[0].rsplit('/', 1)[-1].rsplit('_', 1)[0][3:]).datetime\n",
    "                closest_flare = GetClosestFlareToDatetime(predicted_start_time)\n",
    "                model = end_model\n",
    "                start_predict_error = abs(predicted_start_time-parse_time(closest_flare['event_starttime'], precision=0).datetime)\n",
    "                start_total_error_time += start_predict_error\n",
    "                predicted_flares += 1\n",
    "                \n",
    "                logfile.write(f'predicted flare START: {predicted_start_time} class {cur_flare_class}\\n')\n",
    "                logfile.write(f\"closest true flare START: {closest_flare['event_starttime']} class {closest_flare['fl_goescls']}\\n\")\n",
    "                logfile.write(f\"error: {start_predict_error}\\n\")\n",
    "                logfile.write('--------------------------------------------------------------\\n')\n",
    "            elif model == end_model:\n",
    "                # Flare end detected\n",
    "                predicted_end_time = parse_time(filepaths[i-sequence_length].rsplit('.', 1)[0].rsplit('/', 1)[-1].rsplit('_', 1)[0][3:]).datetime\n",
    "                model = start_model\n",
    "                end_predict_error = abs(predicted_start_time-parse_time(closest_flare['event_endtime'], precision=0).datetime)\n",
    "                end_total_error_time += end_predict_error\n",
    "                \n",
    "                logfile.write(f'predicted flare END: {predicted_start_time} class {cur_flare_class}\\n')\n",
    "                logfile.write(f\"closest true flare END: {closest_flare['event_endtime']} class {closest_flare['fl_goescls']}\\n\")\n",
    "                logfile.write(f\"error: {end_predict_error}\\n\")\n",
    "                logfile.write('--------------------------------------------------------------\\n')\n",
    "    logfile.write(f'average start error time: {start_total_error_time/predicted_flares}\\n')\n",
    "    logfile.write(f'average end error time: {end_total_error_time/predicted_flares}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "989e855f-8e5f-4705-8656-a95fd1169015",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CalculateDetectionErrorSingleModel(months_filepaths, start_model, flare_classes, image_size=64, sequence_length=5):\n",
    "    # os.remove(f'./logs/flare_detections/flare_detections_single_model.txt')\n",
    "    # os.remove(f'./logs/flare_detections/flare_detections_single_model_full_log.txt')\n",
    "    global_logfile = open(f'./logs/flare_detections/flare_detections_averages.txt', 'w')\n",
    "    # logfile = open(f'./logs/flare_detections/flare_detections_single_model.txt', 'a')\n",
    "    base_logfile_name = f'./logs/flare_detections/flare_detections_single_model'\n",
    "    base_pred_logfile_name = f'./logs/flare_detections/flare_detections_single_model_full_log'\n",
    "    # pred_logfile = open(f'./logs/flare_detections/flare_detections_single_model_full_log.txt', 'a')\n",
    "    start_total_error_time = datetime.timedelta(seconds=0)\n",
    "    end_total_error_time = datetime.timedelta(seconds=0)\n",
    "    total_predicted_flares = 0\n",
    "    \n",
    "    for mi, filepaths in enumerate(months_filepaths):\n",
    "        month_logfile = open(f'{base_logfile_name}_{mi+1}.txt', 'w')\n",
    "        month_pred_logfile = open(f'{base_pred_logfile_name}_{mi+1}.txt', 'w')\n",
    "        print(f'processing month {mi+1}')\n",
    "        model = start_model\n",
    "        cur_flare_location = None\n",
    "        closest_flare = None\n",
    "        cur_flare_class = 'N'\n",
    "        predicted_flares = 0\n",
    "        detected_mode = False\n",
    "        consecutive_preds = 0\n",
    "        images_raw = [np.load(x)['x'] for x in filepaths]\n",
    "        images_raw_diff = [abs(images_raw[x]-images_raw[x-1]) for x in range(1, len(images_raw))]\n",
    "        images_diff = [cv2.resize(x, (image_size, image_size), interpolation = cv2.INTER_AREA) for x in images_raw_diff]\n",
    "        predicted_start_time, predicted_end_time = None, None\n",
    "        month_average_start_error, month_average_end_error = datetime.timedelta(seconds=0), datetime.timedelta(seconds=0)\n",
    "        \n",
    "\n",
    "        for idx, i in enumerate(range(sequence_length, len(images_diff))):\n",
    "            past_images = images_diff[i-sequence_length:i]\n",
    "            past_images = np.array(past_images)\n",
    "            past_images = np.expand_dims(past_images, 0)\n",
    "            past_images = np.expand_dims(past_images, 4)\n",
    "            # now the shape is 1, 12, 64, 64, 1 of full sun images\n",
    "            prediction = model.predict(past_images, verbose=0)\n",
    "            pos = prediction[0].argmax()\n",
    "            cur_flare_class = flare_classes[pos]#PosToClass(pos, flare_classes)\n",
    "\n",
    "            month_pred_logfile.write(f'from: {GetCleanAIAFilename(filepaths[i-sequence_length])} to: {GetCleanAIAFilename(filepaths[i+1])}\\n')\n",
    "            month_pred_logfile.write(str(prediction[0])+'\\n')\n",
    "            month_pred_logfile.write(str(pos)+'\\n')\n",
    "            month_pred_logfile.write('--------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "            time_string = filepaths[i-sequence_length].rsplit('.', 1)[0].rsplit('/', 1)[-1].rsplit('_', 1)[0][3:]\n",
    "            year, month, day, hour, minute = int(time_string[:4]), int(time_string[4:6]), int(time_string[6:8]), int(time_string[9:11]), int(time_string[11:13])\n",
    "\n",
    "            if pos > 0:\n",
    "                if detected_mode:\n",
    "                    consecutive_preds += 1\n",
    "                    continue\n",
    "                # flare start detected\n",
    "                detected_mode = True\n",
    "                # Flare detected\n",
    "\n",
    "                time_string = filepaths[i-sequence_length].rsplit('.', 1)[0].rsplit('/', 1)[-1].rsplit('_', 1)[0][3:]\n",
    "                year, month, day, hour, minute = int(time_string[:4]), int(time_string[4:6]), int(time_string[6:8]), int(time_string[9:11]), int(time_string[11:13])\n",
    "                predicted_start_time = datetime.datetime(year, month, day, hour, minute)\n",
    "                \n",
    "                try:\n",
    "                    closest_flare = GetClosestFlareToDatetime(predicted_start_time)\n",
    "                except:\n",
    "                    break\n",
    "                # model = end_model\n",
    "                start_predict_error = abs(predicted_start_time-parse_time(closest_flare['event_starttime'], precision=0).datetime)\n",
    "                start_total_error_time += start_predict_error\n",
    "                month_average_start_error += start_predict_error\n",
    "                predicted_flares += 1\n",
    "                total_predicted_flares += 1\n",
    "                consecutive_preds += 1\n",
    "                month_logfile.write(f'predicted flare START: {predicted_start_time} class {cur_flare_class}\\n')\n",
    "                month_logfile.write(f\"closest true flare START: {closest_flare['event_starttime']} class {closest_flare['fl_goescls']}\\n\")\n",
    "                month_logfile.write(f\"error: {start_predict_error}\\n\")\n",
    "                month_logfile.write('--------------------------------------------------------------\\n')\n",
    "\n",
    "            elif pos == 0:\n",
    "                if detected_mode:\n",
    "                    if consecutive_preds < 2:\n",
    "                        consecutive_preds = 0\n",
    "                        detected_mode = False\n",
    "                        continue\n",
    "                    # flare end detected\n",
    "                    time_string = filepaths[i-sequence_length].rsplit('.', 1)[0].rsplit('/', 1)[-1].rsplit('_', 1)[0][3:]\n",
    "                    year, month, day, hour, minute = int(time_string[:4]), int(time_string[4:6]), int(time_string[6:8]), int(time_string[9:11]), int(time_string[11:13])\n",
    "                    predicted_end_time = datetime.datetime(year, month, day, hour, minute) + datetime.timedelta(minutes=-6)\n",
    "\n",
    "\n",
    "                    # model = start_model\n",
    "                    end_predict_error = abs(predicted_end_time-parse_time(closest_flare['event_endtime'], precision=0).datetime)\n",
    "                    end_total_error_time += end_predict_error\n",
    "                    month_average_end_error += end_predict_error\n",
    "\n",
    "                    month_logfile.write(f'predicted flare END: {predicted_end_time} class {cur_flare_class}\\n')\n",
    "                    month_logfile.write(f\"closest true flare END: {closest_flare['event_endtime']} class {closest_flare['fl_goescls']}\\n\")\n",
    "                    month_logfile.write(f\"error: {end_predict_error}\\n\")\n",
    "                    month_logfile.write('--------------------------------------------------------------\\n')\n",
    "                consecutive_preds = 0\n",
    "                detected_mode = False\n",
    "        month_logfile.write(f'\\naverage month start error time: {month_average_start_error/predicted_flares}\\n')\n",
    "        month_logfile.write(f'average month end error time: {month_average_end_error/predicted_flares}\\n')\n",
    "        month_logfile.close()\n",
    "        month_pred_logfile.close()\n",
    "    \n",
    "    global_logfile.write(f'average start error time: {start_total_error_time/total_predicted_flares}\\n')\n",
    "    global_logfile.write(f'average end error time: {end_total_error_time/total_predicted_flares}\\n')\n",
    "    \n",
    "    global_logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2c824b-02d7-4dd0-95e5-e86bee9a573c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WriteVideo(frames_dir, video_name):\n",
    "    paths = []\n",
    "    for subdir, dirs, files in os.walk(frames_dir):\n",
    "        for f in files:\n",
    "            if f.rsplit('.', 1)[-1] == 'png':\n",
    "                paths.append(os.path.join(subdir, f))\n",
    "        break\n",
    "    paths = sorted(paths, key=key_func)\n",
    "    writer = imageio.get_writer(f'{VIDEOS_DIR}/{video_name}.mp4', fps=8)\n",
    "    for file in paths:\n",
    "        im = imageio.imread(file)\n",
    "        if im.shape != (512, 512, 4):\n",
    "            print(im.shape)\n",
    "            continue\n",
    "        writer.append_data(im)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01fb8d73-b324-4c67-a623-0c9173d6157f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def WritePredictedImages(save_dir, title, filepaths, flare_classes, rect_size=64):\n",
    "    delete_files(save_dir)\n",
    "    images_raw = [np.load(x)['x'] for x in filepaths]\n",
    "    \n",
    "    for im in images_raw:\n",
    "        irradiance = im.max()\n",
    "        \n",
    "\n",
    "        draw = ImageDraw.Draw(first_image_pil)\n",
    "        if pos > 1:\n",
    "            first_image_raw = past_images_raw[0]\n",
    "            center_coord = GetImageTopNRegionsCoords(first_image_raw, 1)[0]\n",
    "            tl, br = (center_coord[1]-rect_size//2, center_coord[0]-rect_size//2), (center_coord[1]+rect_size//2, center_coord[0]+rect_size//2)\n",
    "            draw.rectangle((tl, br), outline=\"red\")\n",
    "        filename = filepaths[i-sequence_length].rsplit('/')[-1].rsplit('.', 1)[0]\n",
    "        draw.text((12, 490),filename,(255,255,255))\n",
    "        draw.text((400, 490),PosToClass(pos),(255,255,255))\n",
    "        first_image_pil.save(f'{save_dir}/{i-sequence_length}.png', \"PNG\")\n",
    "    logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3def34ae-acdd-4ea0-a6e9-fbb4d1607285",
   "metadata": {},
   "outputs": [],
   "source": [
    "flare_classes=['H', 'M', 'X']\n",
    "start_datetime, end_datetime = datetime.datetime(2013, 5, 1), datetime.datetime(2013, 5, 31)\n",
    "filepaths = GetFilepathsBetweenDates(start_datetime, end_datetime, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f4c6e79-87a1-4a93-8dca-9ac1ff1c10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_disk_model = tf.keras.models.load_model(f'./best_trained_models/ALL_lstm_data_nmx_during_leftout2013_cadence6.h5')\n",
    "cutout_model = tf.keras.models.load_model(f'./best_trained_models/HMX_cadence6_frame6_binary.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2868fc58-35fb-4b8b-8a20-e0c2e8b3f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WritePredictedImages(FRAMES_MARKED_DIR, 'new_NMX_test', filepaths, full_disk_model, flare_classes, image_size=64, sequence_length=5, rect_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "809872aa-ba7f-485e-8a1c-e84564de4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_point = 'AIA20130109_1434_0094'\n",
    "# full = []\n",
    "# for subdir, dirs, files in os.walk(f'./new_data/cadence6_frame6/val/H/{data_point}/0/full'):\n",
    "#     for f in files:\n",
    "#         full.append(os.path.join(subdir, f))\n",
    "# cutouts = []\n",
    "# for subdir, dirs, files in os.walk(f'./new_data/cadence6_frame6/val/H/{data_point}/0/sequence'):\n",
    "#     for f in files:\n",
    "#         cutouts.append(os.path.join(subdir, f))\n",
    "        \n",
    "# full = sorted(full)\n",
    "# cutouts = sorted(cutouts)\n",
    "# full = [np.load(x) for x in full]\n",
    "# cutouts = [np.load(x) for x in cutouts]\n",
    "# full = [abs(abs(full[x]) - abs(full[x - 1])) for x in range(1, 6)]\n",
    "# cutouts = [abs(abs(cutouts[x]) - abs(cutouts[x - 1])) for x in range(1, 6)]\n",
    "# full = [cv2.resize(x, (64, 64), interpolation = cv2.INTER_AREA) for x in full]\n",
    "# merged = np.concatenate([full, cutouts])\n",
    "# merged = np.expand_dims(merged, 0)\n",
    "# merged = np.expand_dims(merged, 4)\n",
    "# cutout_model.predict(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c91f7be-d7a8-4786-ac1d-d269f236c888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WritePredictedCutouts(CUTOUT_FRAMES_MARKED, filepaths, full_disk_model, cutout_model, flare_classes, image_size=64, sequence_length=5, stride=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b01cc05-ace1-4ced-8efb-790f1d029691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11479/1067415504.py:11: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  im = imageio.imread(file)\n"
     ]
    }
   ],
   "source": [
    "WriteVideo(CUTOUT_FRAMES_MARKED, 'final_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23e54f6f-1d66-4076-9638-204c0b122061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(2, 3, figsize=(10, 8))\n",
    "\n",
    "# for idx, ax in enumerate(axes.flat):\n",
    "#     ax.imshow(trc[2][idx], cmap='jet')\n",
    "#     ax.set_title(f\"Frame {idx + 1}\")\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51de76-d129-44a0-a1a6-7353a67061be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CalculateDetectionError(filepaths, start_model, end_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df1b40-f8d6-4d11-ba1d-ca85b65b7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CalculateDetectionErrorSingleModel(filepaths, start_model, flare_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "755c719e-9183-44d2-9831-406443ff916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_title = 'ALL_lstm_data_nmx_during_leftout2013_cadence6'\n",
    "# # start_model = tf.keras.models.load_model(f'./best_trained_models/ALL_lstm_data_hmx_new_during_leftout2013_cadence6.h5')\n",
    "# # end_model = tf.keras.models.load_model(f'./best_trained_models/ALL_lstm_data_nmx_end_leftout2013_cadence6.h5')\n",
    "# batch_size, sequence_length, image_size, num_classes = 128, 6, 64, 3\n",
    "# # start_datetime, end_datetime = datetime.datetime(2016, 1, 1), datetime.datetime(2016, 1, 3)\n",
    "# start_datetime, end_datetime = datetime.datetime(2013, 5, 2), datetime.datetime(2013, 5, 31)\n",
    "# filepaths = GetFilepathsBetweenDates(start_datetime, end_datetime, 6)\n",
    "# model = tf.keras.models.load_model(f'./best_trained_models/{data_title}.h5')\n",
    "# # model = ConvLSTMModelAllClass(batch_size, image_size, sequence_length-1, num_classes)\n",
    "# # model.load_weights(f'{LSTM_CHECKPOINTS_DIR}/full_image_duringflare_nmx_leftout2013_bidirectional_convlstm')\n",
    "# # WriteStartEndImages(FRAMES_MARKED_DIR, data_title, filepaths, start_model, end_model, image_size=64, sequence_length=sequence_length-1, rect_size=64)\n",
    "\n",
    "# WritePredictedImages(FRAMES_MARKED_DIR, data_title, filepaths, model, flare_classes, image_size=64, sequence_length=sequence_length-1, rect_size=64)\n",
    "# # WritePredictedCutouts(CUTOUT_FRAMES_MARKED, filepaths, model, image_size=64, sequence_length=sequence_length-1)\n",
    "# # video_title = f'full_image_{parse_time(start_datetime, precision=0).fits}~{parse_time(end_datetime, precision=0).fits}'\n",
    "# WriteVideo(FRAMES_MARKED_DIR, data_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bce4c106-6a0d-4ee8-b0e9-da7fd7ec0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConvLSTMModelAllClass(batch_size, image_size, sequence_length)\n",
    "# model.load_weights(f'{LSTM_CHECKPOINTS_DIR}/cutout_image_duringflare_bidirectional_convlstm')\n",
    "# # c = WritePredictedCutouts(CUTOUT_FRAMES_MARKED, filepaths, model, image_size=64, sequence_length=5)\n",
    "# video_title = f'full_image_{parse_time(start_datetime, precision=0).fits}~{parse_time(end_datetime, precision=0).fits}'\n",
    "# WriteVideo(CUTOUT_FRAMES_MARKED, video_title)sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bb70c4f-26af-4552-a18d-a5d529b5c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateAIAVideo(start_datetime, end_datetime):\n",
    "    # filepaths = GetFilepathsBetweenDates(start_datetime, end_datetime)\n",
    "    # WriteImages(filepaths)\n",
    "    WriteVideo(FRAMES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab4517-f907-4e47-9c30-4640e2714f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawRectangle(img, top_left, bottom_right, save_dir):\n",
    "    result = img.copy()\n",
    "    result = cv2.rectangle(result, coord1, coord2, color=(0, 0, 255), thickness=3)\n",
    "    cv2.imwrite(save_dir, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e12638-8e56-4461-b066-8bc4ea7b9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateAIAVideoPrediction(start_datetime, end_datetime, model):\n",
    "    filepaths = GetFilepathsBetweenDates(start_datetime, end_datetime)\n",
    "    return WritePredictedImages(filepaths, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "541a660e-f452-4442-bca7-46e8bec67e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_datetime, end_datetime = datetime.datetime(2016, 1, 1), datetime.datetime(2016, 1, 3)\n",
    "# model = ConvLSTMModel(64)\n",
    "# model.load_weights(f'{LSTM_CHECKPOINTS_DIR}/conv_lstm_trial_5')\n",
    "# # end_model = ConvLSTMModel(64)\n",
    "# # end_model.load_weights(f'{LSTM_CHECKPOINTS_DIR}/conv_lstm_trial_end_full')\n",
    "# delete_files(FRAMES_MARKED_DIR)\n",
    "# CreateAIAVideoPrediction(start_datetime, end_datetime, model)\n",
    "# WriteVideo(FRAMES_MARKED_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
