{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dae5123-2010-47f4-b44c-a7e7de0b4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import float32\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "sys.path.append(os.path.join(Path.cwd(), 'utils'))\n",
    "sys.path.append(os.path.join(Path.cwd(), 'data_generators'))\n",
    "sys.path.append(os.path.join(Path.cwd(), 'models'))\n",
    "\n",
    "from utils.im_utils import *\n",
    "from utils.data_augmentation import *\n",
    "\n",
    "from data_generators.FullImageBinaryGen import *\n",
    "from data_generators.PairAllClassGen import *\n",
    "from data_generators.FullImageAllClassGen import *\n",
    "from data_generators.CutoutImageAllClassGen import *\n",
    "from data_generators.FullImageSingleClassGen import *\n",
    "\n",
    "from models.bidirectional_convlstm_model import *\n",
    "from models.pair_convlstm_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4536e209-ac28-4772-860d-7188b3baaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7f8eaf-4c5e-4958-a533-b2ea475cd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLARE_CLASS = 'ALL'\n",
    "BEST_TRAINED_MODELS_DIR = './best_trained_models/'\n",
    "\n",
    "LSTM_CHECKPOINTS_DIR = './checkpoints/lstm_checkpoints'\n",
    "RESNET_CHECKPOINTS_DIR = './checkpoints/resnet_checkpoints'\n",
    "\n",
    "# AUG_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/train'\n",
    "# AUG_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/val'\n",
    "# AUG_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/test'\n",
    "\n",
    "TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended/train'\n",
    "VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended/val'\n",
    "TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended/test'\n",
    "\n",
    "AUG_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended_augmented/train'\n",
    "AUG_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended_augmented/val'\n",
    "AUG_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended_augmented/test'\n",
    "\n",
    "AUG_PAIR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_pair/train'\n",
    "AUG_PAIR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_pair/val'\n",
    "AUG_PAIR_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_pair/test'\n",
    "\n",
    "AUG_END_PAIR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_end_data_augmented_pair/train'\n",
    "AUG_END_PAIR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_end_data_augmented_pair/val'\n",
    "AUG_END_PAIR_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_end_data_augmented_pair/test'\n",
    "\n",
    "AUG_ALL_CLASS_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented/train'\n",
    "AUG_ALL_CLASS_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented/val'\n",
    "\n",
    "AUG_ALL_CLASS_PRIOR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_prior/train/'\n",
    "AUG_ALL_CLASS_PRIOR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_prior/val/'\n",
    "\n",
    "# DATA_FEATURES_DIR = './data/data_features_simple'\n",
    "# DATA_FEATURES_TRAIN_DIR = './data/data_features_simple/train'\n",
    "# DATA_FEATURES_VAL_DIR = './data/data_features_simple/val'\n",
    "# DATA_FEATURES_TEST_DIR = './data/data_features_simple/test'\n",
    "\n",
    "LSTM_ALL_CLASS_PRIOR_DATA_DIR = f'./new_data/{FLARE_CLASS}_lstm_data_prior'\n",
    "LSTM_ALL_CLASS_DURING_DATA_DIR = f'./new_data/{FLARE_CLASS}_lstm_data_during'\n",
    "LSTM_ALL_CLASS_LATESTART_DATA_DIR = f'./new_data/{FLARE_CLASS}_lstm_data_latestart'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e86afb-e981-40ed-931f-ee1b92cf5d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1f0a75-96da-4cd9-a534-0e6a985af288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetDataFolders(train_data_dir, val_data_dir):\n",
    "    train_folders = []\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "        for d in dirs:\n",
    "            if d != 'positive' and d != 'negative' and d != '.ipynb_checkpoints':\n",
    "                train_folders.append(os.path.join(subdir, d))\n",
    "    train_folders = np.array(train_folders)\n",
    "\n",
    "    val_folders = []\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "         for d in dirs:\n",
    "                if d != 'positive' and d != 'negative' and d != '.ipynb_checkpoints':\n",
    "                    val_folders.append(os.path.join(subdir, d))\n",
    "    val_folders = np.array(val_folders)\n",
    "    \n",
    "    return train_folders, val_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409cc1c4-2e42-478b-89f4-bbc445a093a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetPairDataFolders(train_data_dir, val_data_dir):\n",
    "    train_folders = set()\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "        for f in files:\n",
    "            flare_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            # if flare_class == 'C':\n",
    "            #     continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            train_folders.add(file_parent_path)\n",
    "\n",
    "    val_folders = set()\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "        for f in files:\n",
    "            flare_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            # if flare_class == 'C':\n",
    "            #     continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            val_folders.add(file_parent_path)\n",
    "    \n",
    "    return list(train_folders), list(val_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66befea-7497-4b21-b562-9caa9d9c0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSingleClassDataFolders(train_data_dir, val_data_dir, flare_class):\n",
    "    train_folders = set()\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "        for f in files:\n",
    "            cur_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            if cur_class != flare_class and cur_class != 'N':\n",
    "                continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            train_folders.add(file_parent_path)\n",
    "\n",
    "    val_folders = set()\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "        for f in files:\n",
    "            cur_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            if cur_class != flare_class and cur_class != 'N':\n",
    "                continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            val_folders.add(file_parent_path)\n",
    "    \n",
    "    return list(train_folders), list(val_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6fe8fc-3204-4bdc-a28a-5e7fe5506fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_labels(generator, feature_extractor):\n",
    "    labels = []\n",
    "\n",
    "    for sample in generator:\n",
    "        new_batch = []\n",
    "        batch = sample[1]\n",
    "        labels.append(batch)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    labels = labels.reshape(labels.shape[0]*labels.shape[1], labels.shape[2])\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d4e3bc-5731-4cdc-bea4-15c642dbc085",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestImageAllClassGen(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        folder_paths,\n",
    "        batch_size,\n",
    "        shuffle=True,\n",
    "        image_size=64,\n",
    "        num_classes=3,\n",
    "        sequence_length=6,\n",
    "    ):\n",
    "\n",
    "        self.folder_paths = folder_paths.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sequence_length = sequence_length\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.n = len(self.folder_paths)\n",
    "        self.n_category = num_classes\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.folder_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batches = self.folder_paths[\n",
    "            index * self.batch_size : (index + 1) * self.batch_size\n",
    "        ]\n",
    "        X, y = self.__get_data(batches)\n",
    "        X = np.expand_dims(X, axis=4)\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    def __get_input(self, folder):\n",
    "        images = []\n",
    "        for subdir, dirs, files in os.walk(folder):\n",
    "            for f in files:\n",
    "                images.append(os.path.join(subdir, f))\n",
    "        images = sorted(images)\n",
    "        images = [np.load(x) for x in images[: self.sequence_length]]\n",
    "        images = [\n",
    "            abs(abs(images[x]) - abs(images[x - 1]))\n",
    "            for x in range(1, self.sequence_length)\n",
    "        ]\n",
    "        images = [\n",
    "            cv2.resize(\n",
    "                x, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "            for x in images\n",
    "        ]\n",
    "        images = np.array(images)\n",
    "        return images\n",
    "\n",
    "    def __get_output(self, path):\n",
    "        label = None\n",
    "        folder = path.rsplit(\"/\")[-3]\n",
    "        if folder == \"N\":\n",
    "            label = 0\n",
    "        elif folder == 'C':\n",
    "            label = 1\n",
    "        elif folder == \"M\":\n",
    "            label = 2\n",
    "        elif folder == \"X\":\n",
    "            label = 3\n",
    "\n",
    "        one_hot_label = tf.one_hot(label, self.n_category)\n",
    "\n",
    "        return one_hot_label\n",
    "\n",
    "    def __get_data(self, batches):\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in batches])\n",
    "        y_batch = np.asarray([self.__get_output(y) for y in batches])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04bdc844-9b6c-4af4-b11e-407f23054336",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_classes=2\n",
    "sequence_length=6\n",
    "data_dir = 'ALL_lstm_data_ncmx_during_leftout2013_cadence6'\n",
    "output_name = 'ALL_lstm_data_nx_during_leftout2013_cadence6'\n",
    "train_dir = os.path.join(f'./new_data/{data_dir}/', 'train')\n",
    "val_dir = os.path.join(f'./new_data/{data_dir}/', 'val')\n",
    "train_folders, val_folders = GetSingleClassDataFolders(train_dir, val_dir, 'X')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc6112f-1864-49ba-8a56-c37e428fafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = FullImageSingleClassGen(train_folders, batch_size=batch_size, image_size=64, num_classes=num_classes, sequence_length=sequence_length, flare_class='X')\n",
    "valgen = FullImageSingleClassGen(val_folders, batch_size=1, image_size=64, num_classes=num_classes, sequence_length=sequence_length, flare_class='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346ba04b-c740-4689-b51e-e1457e5caa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_vals = [x[1] for x in valgen]\n",
    "# true_vals = np.concatenate(true_vals)\n",
    "# true_labels = [x.argmax() for x in true_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "445585ec-f864-40f1-ac47-c33a0d6d0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(f'./best_trained_models/{data_dir}.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fccaef28-037a-4724-979a-f00c90b1a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(valgen)\n",
    "# pred_labels = [x.argmax() for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "056e3dcb-17f1-4177-ad43-0a3d83d423a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# for i, l in enumerate(pred_labels):\n",
    "#      if l == true_labels[i]:\n",
    "#             c+=1\n",
    "# print(c/len(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38531a26-0bf3-4084-ad79-2fb27e7bc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.math.confusion_matrix(\n",
    "#     true_labels,\n",
    "#     pred_labels,\n",
    "#     num_classes=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9efb6fc-daba-480e-b53e-38c5ca67d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = {}\n",
    "# valid_classes = ['N', 'C', 'M', 'X']\n",
    "\n",
    "# for folder in val_folders:\n",
    "#     for subdir, dirs, files in os.walk(folder):\n",
    "#         flare_class = subdir.rsplit('/')[-3]\n",
    "#         if flare_class in valid_classes:\n",
    "#             if flare_class in classes:\n",
    "#                 classes[flare_class]+=1\n",
    "#             else:\n",
    "#                 classes[flare_class]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6362c1d-f97b-426b-b73b-da9a11d8caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traingen\n",
    "# N tuples representing N batches\n",
    "# each tuple is value, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0efb5ff-e3d4-489d-8742-2768769debc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 64, 64, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 16:27:43.788526: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-15 16:27:44.420202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 47223 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:82:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = ConvLSTMModelAllClass(batch_size, 64, sequence_length-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f38617da-57b0-42e4-86dd-19c6d379b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 64, 64, 1)]    0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 5, 64, 64, 64)     519680    \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 5, 62, 62, 128)    73856     \n",
      "                                                                 \n",
      " global_max_pooling3d (Globa  (None, 128)              0         \n",
      " lMaxPooling3D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610,306\n",
      "Trainable params: 610,050\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde25104-b946-46e7-9e01-6d974cc54af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(f'{BEST_TRAINED_MODELS_DIR}/{output_name}.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f5df617-bd75-48fd-adb0-92949f783420",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [mc]\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "    tfa.metrics.F1Score(num_classes=num_classes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6dd8550-4528-4a1e-856e-6e3b4c970244",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_fine = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "initial_learning_rate=1e-3,\n",
    "decay_steps=10000,\n",
    "decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=adam_fine, metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817e658-d8df-4fca-8621-edcd816f97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 16:28:17.323410: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-09-15 16:28:17.976511: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-09-15 16:28:17.981109: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/171 [..............................] - ETA: 6:15 - loss: 6.1302 - categorical_accuracy: 0.4531 - precision: 0.4531 - recall: 0.4531 - f1_score: 0.4528    "
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(traingen, validation_data=valgen, epochs=epochs, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ec9e4-4b18-466b-8fdf-c6d7ac0ff9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d53c9-ca65-4900-96cc-f586fdb8fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f85a4e-dc67-4d7d-ab49-fda2b18603db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'{LSTM_CHECKPOINTS_DIR}/{output_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226c8f7-28b0-4f19-9202-c82c76c56840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = './new_data/ALL_lstm_data_during_leftout2013/train/M/AIA20100807_1748_0094/0/full'\n",
    "# paths = []\n",
    "# for subdir, dirs, files in os.walk(data_folder):\n",
    "#     for f in files:\n",
    "#         paths.append(os.path.join(subdir, f))\n",
    "# paths = sorted(paths)\n",
    "# for p in paths:\n",
    "#     print(p)\n",
    "\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(10, 8))\n",
    "\n",
    "# for idx, ax in enumerate(axes.flat):\n",
    "#     ax.imshow(np.squeeze(preprocessing.normalize(np.load(paths[idx]))), cmap='jet')\n",
    "#     ax.set_title(f\"Frame {idx + 1}\")\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
