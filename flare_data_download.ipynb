{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ce2bb9-cbd7-4110-b104-657f2d4b7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.net import Fido\n",
    "from sunpy.time import parse_time\n",
    "\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989444dd-7824-4f2c-afd9-7e758553765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLARE_CSV_DIR = './event_records/all_flare_events_year'\n",
    "EVENTS_BY_DATE_DIR = './event_records/all_flare_events_date'\n",
    "EVENTS_BY_YEAR_DIR = './event_records/events_by_year'\n",
    "NEW_EVENTS_BY_DATE_DIR = './event_records/new_events_by_date'\n",
    "NEW_EVENTS_BY_CLASS_DIR = './event_records/new_events_by_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba32c98-8701-4e8e-bd66-2c1b554ebe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_goes_year(year):\n",
    "    print(year)\n",
    "    t_start = datetime.datetime(year=year, month=1, day=1)\n",
    "    t_end = datetime.datetime(year=year+1, month=1, day=1)\n",
    "    results = Fido.search(\n",
    "        a.Time(t_start, t_end),\n",
    "        a.hek.EventType(\"FL\"),\n",
    "    )\n",
    "    if not results.all_colnames: # no columns / no results\n",
    "        return None\n",
    "\n",
    "    event_table = results['hek'][\n",
    "        'event_starttime'\n",
    "        , 'event_endtime'\n",
    "        , 'fl_goescls'\n",
    "        , 'hpc_coord'\n",
    "        , 'hpc_bbox'\n",
    "        , 'hrc_coord'\n",
    "        , 'hrc_bbox'\n",
    "        , 'hgc_coord'\n",
    "        , 'hgc_bbox'\n",
    "        , 'event_coordsys'\n",
    "        , 'hgs_coord'\n",
    "        , 'hgs_bbox'\n",
    "        , 'event_peaktime'\n",
    "        , 'active'\n",
    "        , 'ar_noaaclass'\n",
    "        , 'ar_noaanum'\n",
    "        , 'boundbox_c1ur'\n",
    "        , 'boundbox_c2ur'\n",
    "        , 'boundbox_c1ll'\n",
    "        , 'boundbox_c2ll'\n",
    "        , 'hpc_y'\n",
    "        , 'hpc_x'\n",
    "        , 'hgs_y'\n",
    "        , 'hgs_x'\n",
    "        , 'hpc_radius'\n",
    "        , 'event_c2error'\n",
    "    ]\n",
    "    \n",
    "    return event_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cdec849-59bf-423a-9707-991916ec4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goes_query_to_df(query):\n",
    "    event_df = query.to_pandas()\n",
    "\n",
    "    if len(event_df) == 0:\n",
    "        return None\n",
    "\n",
    "    return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb744134-eb13-4a60-a9fd-719e0e019146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goes_flares_to_csv(start_year, end_year):\n",
    "    if not os.path.exists(FLARE_CSV_DIR):\n",
    "        os.makedirs(FLARE_CSV_DIR)\n",
    "    \n",
    "    for year in range(start_year, end_year+1):\n",
    "        flares_table = query_goes_year(year)\n",
    "        flares_df = goes_query_to_df(flares_table)\n",
    "        flares_csv_path = os.path.join(FLARE_CSV_DIR, f'{str(year)}.csv') \n",
    "        flares_df.to_csv(flares_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2a24a7-b651-4d89-be70-43be9c23f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateEventByDateCSV(flares_by_year_dir, save_dir):\n",
    "    year_dict = {}\n",
    "    \n",
    "    for f in os.scandir(flares_by_year_dir):\n",
    "        if f.is_file():\n",
    "            year_df = pd.read_csv(f)\n",
    "            \n",
    "            for index, row in year_df.iterrows():\n",
    "                dt = parse_time(row['event_starttime'])\n",
    "                year, month = dt.datetime.year, dt.datetime.month\n",
    "            \n",
    "                if year in year_dict:\n",
    "                    if month in year_dict[year]:\n",
    "                        month_df = pd.DataFrame([row])\n",
    "                        year_dict[year][month] = pd.concat([year_dict[year][month], month_df])\n",
    "                    else:\n",
    "                        month_df = pd.DataFrame([row])\n",
    "                        year_dict[year][month] = month_df\n",
    "                else:\n",
    "                    month_df = pd.DataFrame([row])\n",
    "                    year_dict[year] = {month: month_df}\n",
    "    \n",
    "    # iterate over years\n",
    "    for k, v in year_dict.items():\n",
    "        year_folder_dir = os.path.join(save_dir, str(k))\n",
    "\n",
    "        if not os.path.exists(year_folder_dir):\n",
    "            os.makedirs(year_folder_dir)\n",
    "        \n",
    "        # iterate over months\n",
    "        for k1, v1 in v.items():\n",
    "            event_path_csv_dir = os.path.join(save_dir, f'{str(k)}/{str(k1)}.csv')\n",
    "            if os.path.exists(event_path_csv_dir):\n",
    "                v1.to_csv(event_path_csv_dir, mode='a', index=False)\n",
    "            else:\n",
    "                v1.to_csv(event_path_csv_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d371b11-a8fb-4b66-9889-f7bba62bfb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateEventByClassCSV(flares_by_year_dir, save_dir):\n",
    "    class_dict = {}\n",
    "    \n",
    "    for f in os.scandir(flares_by_year_dir):\n",
    "        if f.is_file():\n",
    "            year_df = pd.read_csv(f)\n",
    "            \n",
    "            for index, row in year_df.iterrows():\n",
    "                e_class = row['fl_goescls']\n",
    "                e_class = list(e_class)[0]\n",
    "                \n",
    "                if e_class in class_dict:\n",
    "                    class_df = pd.DataFrame([row])\n",
    "                    class_dict[e_class] = pd.concat([class_dict[e_class], class_df])\n",
    "                \n",
    "                else:\n",
    "                    class_df = pd.DataFrame([row])\n",
    "                    class_dict[e_class] = class_df\n",
    "            \n",
    "                \n",
    "    \n",
    "    # iterate over years\n",
    "    for k, v in class_dict.items():\n",
    "        class_csv_dir = os.path.join(save_dir, f'{str(k)}.csv')\n",
    "\n",
    "        if os.path.exists(class_csv_dir):\n",
    "            v.to_csv(class_csv_dir, mode='a', index=False)\n",
    "        else:\n",
    "            v.to_csv(class_csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae948b24-fd43-4e68-b282-703aea38f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_csv = pd.read_csv('./event_records/new_events_by_class/X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccabf7be-b0a1-4066-8978-38374eff6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveDuplicateDataEntries(files_dir):\n",
    "    for subdir, dirs, files in os.walk(files_dir):\n",
    "        for f in files:\n",
    "            filepath = os.path.join(subdir, f)\n",
    "            print(filepath)\n",
    "            df = pd.read_csv(filepath)\n",
    "            df.drop_duplicates(subset=['event_starttime', 'fl_goescls'], inplace=True)\n",
    "            df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aeb0960-900b-4bab-bd52-c8c13e8cab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./event_records/new_events_by_class/C.csv\n",
      "./event_records/new_events_by_class/B.csv\n",
      "./event_records/new_events_by_class/X.csv\n",
      "./event_records/new_events_by_class/N.csv\n",
      "./event_records/new_events_by_class/M.csv\n",
      "./event_records/new_events_by_class/A.csv\n",
      "./event_records/new_events_by_class/.ipynb_checkpoints/X-checkpoint.csv\n"
     ]
    }
   ],
   "source": [
    "RemoveDuplicateDataEntries('./event_records/new_events_by_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97fbf593-b483-4db5-8507-17d2fb44325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes_flares_to_csv(2010, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0d33e7-9bbb-4cfd-ae45-b12b9e0fc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CreateEventByDateCSV(EVENTS_BY_YEAR_DIR, NEW_EVENTS_BY_DATE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd18fb1-5718-45d7-9365-d88e456c6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CreateEventByClassCSV(EVENTS_BY_YEAR_DIR, NEW_EVENTS_BY_CLASS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517343ab-b91a-46d7-9d9c-ba914d0baa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
