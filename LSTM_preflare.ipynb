{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dae5123-2010-47f4-b44c-a7e7de0b4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import float32\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "sys.path.append(os.path.join(Path.cwd(), 'utils'))\n",
    "sys.path.append(os.path.join(Path.cwd(), 'data_generators'))\n",
    "sys.path.append(os.path.join(Path.cwd(), 'models'))\n",
    "\n",
    "from utils.im_utils import *\n",
    "from utils.data_augmentation import *\n",
    "\n",
    "from data_generators.FullImageBinaryGen import *\n",
    "from data_generators.PairAllClassGen import *\n",
    "from data_generators.FullImageAllClassGen import *\n",
    "from data_generators.CutoutImageAllClassGen import *\n",
    "from data_generators.FullImageSingleClassGen import *\n",
    "\n",
    "from models.bidirectional_convlstm_model import *\n",
    "from models.pair_convlstm_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4536e209-ac28-4772-860d-7188b3baaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7f8eaf-4c5e-4958-a533-b2ea475cd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLARE_CLASS = 'ALL'\n",
    "BEST_TRAINED_MODELS_DIR = './best_trained_models/'\n",
    "\n",
    "LSTM_CHECKPOINTS_DIR = './checkpoints/lstm_checkpoints'\n",
    "RESNET_CHECKPOINTS_DIR = './checkpoints/resnet_checkpoints'\n",
    "\n",
    "# AUG_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/train'\n",
    "# AUG_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/val'\n",
    "# AUG_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_data_augmented/test'\n",
    "\n",
    "TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended/train'\n",
    "VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended/val'\n",
    "TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended/test'\n",
    "\n",
    "AUG_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended_augmented/train'\n",
    "AUG_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended_augmented/val'\n",
    "AUG_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_extended_augmented/test'\n",
    "\n",
    "AUG_PAIR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_pair/train'\n",
    "AUG_PAIR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_pair/val'\n",
    "AUG_PAIR_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_pair/test'\n",
    "\n",
    "AUG_END_PAIR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_end_data_augmented_pair/train'\n",
    "AUG_END_PAIR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_end_data_augmented_pair/val'\n",
    "AUG_END_PAIR_TEST_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_end_data_augmented_pair/test'\n",
    "\n",
    "AUG_ALL_CLASS_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented/train'\n",
    "AUG_ALL_CLASS_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented/val'\n",
    "\n",
    "AUG_ALL_CLASS_PRIOR_TRAIN_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_prior/train/'\n",
    "AUG_ALL_CLASS_PRIOR_VAL_DATA_DIR = f'./data/{FLARE_CLASS}_lstm_data_augmented_prior/val/'\n",
    "\n",
    "# DATA_FEATURES_DIR = './data/data_features_simple'\n",
    "# DATA_FEATURES_TRAIN_DIR = './data/data_features_simple/train'\n",
    "# DATA_FEATURES_VAL_DIR = './data/data_features_simple/val'\n",
    "# DATA_FEATURES_TEST_DIR = './data/data_features_simple/test'\n",
    "\n",
    "LSTM_ALL_CLASS_PRIOR_DATA_DIR = f'./new_data/{FLARE_CLASS}_lstm_data_prior'\n",
    "LSTM_ALL_CLASS_DURING_DATA_DIR = f'./new_data/{FLARE_CLASS}_lstm_data_during'\n",
    "LSTM_ALL_CLASS_LATESTART_DATA_DIR = f'./new_data/{FLARE_CLASS}_lstm_data_latestart'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e86afb-e981-40ed-931f-ee1b92cf5d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_files(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1f0a75-96da-4cd9-a534-0e6a985af288",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetDataFolders(train_data_dir, val_data_dir):\n",
    "    train_folders = []\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "        for d in dirs:\n",
    "            if d != 'positive' and d != 'negative' and d != '.ipynb_checkpoints':\n",
    "                train_folders.append(os.path.join(subdir, d))\n",
    "    train_folders = np.array(train_folders)\n",
    "\n",
    "    val_folders = []\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "         for d in dirs:\n",
    "                if d != 'positive' and d != 'negative' and d != '.ipynb_checkpoints':\n",
    "                    val_folders.append(os.path.join(subdir, d))\n",
    "    val_folders = np.array(val_folders)\n",
    "    \n",
    "    return train_folders, val_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409cc1c4-2e42-478b-89f4-bbc445a093a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetFlaresDataFolders(train_data_dir, val_data_dir, flare_classes):\n",
    "    train_folders = set()\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "        for f in files:\n",
    "            flare_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            if flare_class not in flare_classes:\n",
    "                continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            train_folders.add(file_parent_path)\n",
    "\n",
    "    val_folders = set()\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "        for f in files:\n",
    "            flare_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            if flare_class not in flare_classes:\n",
    "                continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            val_folders.add(file_parent_path)\n",
    "    \n",
    "    return list(train_folders), list(val_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66befea-7497-4b21-b562-9caa9d9c0225",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetSingleClassDataFolders(train_data_dir, val_data_dir, flare_class):\n",
    "    train_folders = set()\n",
    "    for subdir, dirs, files in os.walk(train_data_dir):\n",
    "        for f in files:\n",
    "            cur_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            if cur_class != flare_class and cur_class != 'N':\n",
    "                continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            train_folders.add(file_parent_path)\n",
    "\n",
    "    val_folders = set()\n",
    "    for subdir, dirs, files in os.walk(val_data_dir):\n",
    "        for f in files:\n",
    "            cur_class = os.path.join(subdir, f).rsplit('/')[-5]\n",
    "            if cur_class != flare_class and cur_class != 'N':\n",
    "                continue\n",
    "            file_parent_path = os.path.join(subdir, f).rsplit('/', 2)[0]\n",
    "            val_folders.add(file_parent_path)\n",
    "    \n",
    "    return list(train_folders), list(val_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6fe8fc-3204-4bdc-a28a-5e7fe5506fcf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_labels(generator, feature_extractor):\n",
    "    labels = []\n",
    "\n",
    "    for sample in generator:\n",
    "        new_batch = []\n",
    "        batch = sample[1]\n",
    "        labels.append(batch)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    labels = labels.reshape(labels.shape[0]*labels.shape[1], labels.shape[2])\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d4e3bc-5731-4cdc-bea4-15c642dbc085",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestImageAllClassGen(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        folder_paths,\n",
    "        batch_size,\n",
    "        shuffle=True,\n",
    "        image_size=64,\n",
    "        num_classes=3,\n",
    "        sequence_length=6,\n",
    "    ):\n",
    "\n",
    "        self.folder_paths = folder_paths.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sequence_length = sequence_length\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.n = len(self.folder_paths)\n",
    "        self.n_category = num_classes\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.folder_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batches = self.folder_paths[\n",
    "            index * self.batch_size : (index + 1) * self.batch_size\n",
    "        ]\n",
    "        X, y = self.__get_data(batches)\n",
    "        X = np.expand_dims(X, axis=4)\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    def __get_input(self, folder):\n",
    "        images = []\n",
    "        for subdir, dirs, files in os.walk(folder):\n",
    "            for f in files:\n",
    "                images.append(os.path.join(subdir, f))\n",
    "        images = sorted(images)\n",
    "        images = [np.load(x) for x in images[: self.sequence_length]]\n",
    "        images = [\n",
    "            abs(abs(images[x]) - abs(images[x - 1]))\n",
    "            for x in range(1, self.sequence_length)\n",
    "        ]\n",
    "        images = [\n",
    "            cv2.resize(\n",
    "                x, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "            for x in images\n",
    "        ]\n",
    "        images = np.array(images)\n",
    "        return images\n",
    "\n",
    "    def __get_output(self, path):\n",
    "        label = None\n",
    "        folder = path.rsplit(\"/\")[-3]\n",
    "        if folder == \"N\":\n",
    "            label = 0\n",
    "        elif folder == 'C':\n",
    "            label = 1\n",
    "        elif folder == \"M\":\n",
    "            label = 2\n",
    "        elif folder == \"X\":\n",
    "            label = 3\n",
    "\n",
    "        one_hot_label = tf.one_hot(label, self.n_category)\n",
    "\n",
    "        return one_hot_label\n",
    "\n",
    "    def __get_data(self, batches):\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in batches])\n",
    "        y_batch = np.asarray([self.__get_output(y) for y in batches])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3731a4d9-4653-4e90-b50a-6f28a102fa03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestFullImageAllClassGen(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        folder_paths,\n",
    "        batch_size,\n",
    "        flare_classes,\n",
    "        shuffle=True,\n",
    "        image_size=64,\n",
    "        sequence_length=6,\n",
    "    ):\n",
    "\n",
    "        self.folder_paths = folder_paths.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sequence_length = sequence_length\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.n = len(self.folder_paths)\n",
    "        self.n_category = len(flare_classes)\n",
    "        self.flare_classes = flare_classes\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.folder_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # batches: batches of folder paths to data\n",
    "        batches = self.folder_paths[\n",
    "            index * self.batch_size : (index + 1) * self.batch_size\n",
    "        ]\n",
    "        X, y = self.__get_data(batches)\n",
    "        X = np.expand_dims(X, axis=4)\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    def __get_input(self, folder):\n",
    "        images = []\n",
    "        for subdir, dirs, files in os.walk(folder):\n",
    "            for f in files:\n",
    "                images.append(os.path.join(subdir, f))\n",
    "        images = sorted(images)\n",
    "        images = [np.load(x) for x in images[: self.sequence_length]]\n",
    "        images = [\n",
    "            abs(abs(images[x]) - abs(images[x - 1]))\n",
    "            for x in range(1, self.sequence_length)\n",
    "        ]\n",
    "        images = [\n",
    "            cv2.resize(\n",
    "                x, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "            for x in images\n",
    "        ]\n",
    "        images = np.array(images)\n",
    "        return images\n",
    "\n",
    "    def __get_output(self, path):\n",
    "        label = None\n",
    "        folder = path.rsplit(\"/\")[-3]\n",
    "        folder_index_label = self.flare_classes.index(folder)\n",
    "\n",
    "        one_hot_label = tf.one_hot(folder_index_label, self.n_category)\n",
    "\n",
    "        return one_hot_label\n",
    "\n",
    "    def __get_data(self, batches):\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in batches])\n",
    "        y_batch = np.asarray([self.__get_output(y) for y in batches])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04bdc844-9b6c-4af4-b11e-407f23054336",
   "metadata": {},
   "outputs": [],
   "source": [
    "flare_classes=['N', 'M', 'X']\n",
    "batch_size=128\n",
    "num_classes=len(flare_classes)\n",
    "sequence_length=6\n",
    "data_dir = 'cadence6_frame6'\n",
    "output_name = f\"{''.join(flare_classes)}_{data_dir}\"\n",
    "train_dir = os.path.join(f'./new_data/{data_dir}/', 'train')\n",
    "val_dir = os.path.join(f'./new_data/{data_dir}/', 'val')\n",
    "train_folders, val_folders = GetFlaresDataFolders(train_dir, val_dir, flare_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2009fa54-3c2a-4d75-aa0e-24ebdca7e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = {}\n",
    "# valid_classes = ['N', 'H', 'C', 'M', 'X']\n",
    "\n",
    "# for folder in val_folders:\n",
    "#     for subdir, dirs, files in os.walk(folder):\n",
    "#         flare_class = subdir.rsplit('/')[-3]\n",
    "#         if flare_class in valid_classes:\n",
    "#             if flare_class in classes:\n",
    "#                 classes[flare_class]+=1\n",
    "#             else:\n",
    "#                 classes[flare_class]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc6112f-1864-49ba-8a56-c37e428fafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = TestFullImageAllClassGen(\n",
    "    train_folders, \n",
    "    batch_size, \n",
    "    flare_classes,\n",
    "    image_size=64, \n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "valgen = TestFullImageAllClassGen(\n",
    "    val_folders, \n",
    "    batch_size, \n",
    "    flare_classes,\n",
    "    image_size=64, \n",
    "    sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a100d2-37a1-46ed-adc4-7db2c1539855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 01:06:32.222822: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-17 01:06:34.690856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 47223 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:82:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model(f'./best_trained_models/NCMX_cadence6_frame6.h5')\n",
    "\n",
    "# true_vals = [x[1] for x in valgen]\n",
    "# true_vals = np.concatenate(true_vals)\n",
    "# true_labels = [x.argmax() for x in true_vals]\n",
    "\n",
    "# preds = model.predict(valgen)\n",
    "# pred_labels = [x.argmax() for x in preds]\n",
    "\n",
    "# c = 0\n",
    "# for i, l in enumerate(pred_labels):\n",
    "#      if l == true_labels[i]:\n",
    "#             c+=1\n",
    "# print(c/len(pred_labels))\n",
    "\n",
    "# tf.math.confusion_matrix(\n",
    "#     true_labels,\n",
    "#     pred_labels,\n",
    "#     num_classes=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9efb6fc-daba-480e-b53e-38c5ca67d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = {}\n",
    "# valid_classes = ['N', 'H', 'C', 'M', 'X']\n",
    "\n",
    "# for folder in val_folders:\n",
    "#     for subdir, dirs, files in os.walk(folder):\n",
    "#         flare_class = subdir.rsplit('/')[-3]\n",
    "#         if flare_class in valid_classes:\n",
    "#             if flare_class in classes:\n",
    "#                 classes[flare_class]+=1\n",
    "#             else:\n",
    "#                 classes[flare_class]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6362c1d-f97b-426b-b73b-da9a11d8caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traingen\n",
    "# N tuples representing N batches\n",
    "# each tuple is value, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0efb5ff-e3d4-489d-8742-2768769debc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 64, 64, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 17:30:28.722945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-16 17:30:31.538156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46706 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:82:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = ConvLSTMModelAllClass(batch_size, 64, sequence_length-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f38617da-57b0-42e4-86dd-19c6d379b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 64, 64, 1)]    0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 5, 64, 64, 64)     519680    \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 5, 62, 62, 128)    73856     \n",
      "                                                                 \n",
      " global_max_pooling3d (Globa  (None, 128)              0         \n",
      " lMaxPooling3D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610,564\n",
      "Trainable params: 610,308\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fde25104-b946-46e7-9e01-6d974cc54af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(f'{BEST_TRAINED_MODELS_DIR}/{output_name}.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f5df617-bd75-48fd-adb0-92949f783420",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [mc]\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "    tfa.metrics.F1Score(num_classes=num_classes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6dd8550-4528-4a1e-856e-6e3b4c970244",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_fine = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.0002, amsgrad=False)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "initial_learning_rate=1e-3,\n",
    "decay_steps=10000,\n",
    "decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=adam_fine, metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b817e658-d8df-4fca-8621-edcd816f97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 17:31:01.843245: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-09-16 17:31:02.722854: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-09-16 17:31:02.728357: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24/733 [..............................] - ETA: 55:31 - loss: 2.3573 - categorical_accuracy: 0.4798 - precision: 0.5191 - recall: 0.2747 - f1_score: 0.4441"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilenet_v2_test/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(traingen, validation_data=valgen, epochs=epochs, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ec9e4-4b18-466b-8fdf-c6d7ac0ff9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d53c9-ca65-4900-96cc-f586fdb8fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f85a4e-dc67-4d7d-ab49-fda2b18603db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'{LSTM_CHECKPOINTS_DIR}/{output_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226c8f7-28b0-4f19-9202-c82c76c56840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = './new_data/ALL_lstm_data_during_leftout2013/train/M/AIA20100807_1748_0094/0/full'\n",
    "# paths = []\n",
    "# for subdir, dirs, files in os.walk(data_folder):\n",
    "#     for f in files:\n",
    "#         paths.append(os.path.join(subdir, f))\n",
    "# paths = sorted(paths)\n",
    "# for p in paths:\n",
    "#     print(p)\n",
    "\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(10, 8))\n",
    "\n",
    "# for idx, ax in enumerate(axes.flat):\n",
    "#     ax.imshow(np.squeeze(preprocessing.normalize(np.load(paths[idx]))), cmap='jet')\n",
    "#     ax.set_title(f\"Frame {idx + 1}\")\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
